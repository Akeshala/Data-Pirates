{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from numpy.random import seed\n",
    "seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_preprocessed.csv', header=0)\n",
    "df_test = pd.read_csv('test_preprocessed.csv', header=0)\n",
    "\n",
    "X=df.iloc[:,1:24]\n",
    "y=df.iloc[:,24:25]\n",
    "X_validation_test=df_test.iloc[:,1:24]\n",
    "\n",
    "#check whether some values are missing\n",
    "#X.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(X, y, test_size = 0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Support vector machines\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "\n",
    "clf = svm.SVC(kernel='rbf',degree=2, C=0.4)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "#validation\n",
    "y_pred = clf.predict(x_validation)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_validation, y_pred))\n",
    "print(confusion_matrix(y_validation,y_pred))\n",
    "print(classification_report(y_validation,y_pred))\n",
    "\n",
    "#test\n",
    "y_pred_test = cv.predict(x_validation_test)\n",
    "\n",
    "#normal 0.89 0.45"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#RandomForestGridsearch\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "parameters = {\n",
    "    \"n_estimators\":[5,10,50,100,250],\n",
    "    \"max_depth\":[2,4,8,16,32,None],\n",
    "}\n",
    "cv = GridSearchCV(rfc,parameters,cv=5)\n",
    "cv.fit(x_train, y_train)\n",
    "\n",
    "#validation\n",
    "y_pred = cv.predict(x_validation)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_validation, y_pred))\n",
    "print(confusion_matrix(y_validation,y_pred))\n",
    "print(classification_report(y_validation,y_pred))\n",
    "\n",
    "#test\n",
    "y_pred_test = cv.predict(x_validation_test)\n",
    "\n",
    "#normal - 0.89 0.47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AkeshalaMarasinghe\\.conda\\envs\\HackStat2.0\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8183333333333334\n",
      "[[3545  194]\n",
      " [ 678  383]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.95      0.89      3739\n",
      "         1.0       0.66      0.36      0.47      1061\n",
      "\n",
      "    accuracy                           0.82      4800\n",
      "   macro avg       0.75      0.65      0.68      4800\n",
      "weighted avg       0.80      0.82      0.80      4800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#RandomForestClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf=RandomForestClassifier(n_estimators=100,max_features='auto',random_state=0,\n",
    "                          max_depth=10)\n",
    "clf.fit(x_train,y_train)\n",
    "\n",
    "#validation\n",
    "y_pred = clf.predict(x_validation)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_validation, y_pred))\n",
    "print(confusion_matrix(y_validation,y_pred))\n",
    "print(classification_report(y_validation,y_pred))\n",
    "\n",
    "#test\n",
    "y_pred_test = clf.predict(x_validation_test)\n",
    "\n",
    "#normal 0.89 0.47\n",
    "#o feature fixed 0.89 0.48"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#AdaBoostClassifier\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=9), n_estimators=300,algorithm=\"SAMME.R\", learning_rate=0.0095)\n",
    "ada_clf.fit(x_train,y_train)\n",
    "\n",
    "#validation\n",
    "y_pred = ada_clf.predict(x_validation)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_validation, y_pred))\n",
    "print(confusion_matrix(y_validation,y_pred))\n",
    "print(classification_report(y_validation,y_pred))\n",
    "\n",
    "#test\n",
    "y_pred_test = ada_clf.predict(x_validation_test)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#GradientBoostClassifier\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "model = GradientBoostingClassifier(learning_rate=0.1,max_depth=10,max_features=8,n_estimators=300)\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "#validation\n",
    "y_pred = model.predict(x_validation)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_validation, y_pred))\n",
    "print(confusion_matrix(y_validation,y_pred))\n",
    "print(classification_report(y_validation,y_pred))\n",
    "\n",
    "#test\n",
    "y_pred_test = model.predict(x_validation_test)\n",
    "\n",
    "#normal 0.89 0.47\n",
    "#0 feature fixed 0.88 0.47"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#XGBoostClassifier\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "xgb = XGBClassifier(learning_rate=0.2, max_depth=8,n_estimators= 150,\n",
    " min_child_weight=2, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27,reg_alpha=0.00035) \n",
    "xgb.fit(x_train,y_train)\n",
    "\n",
    "#validation\n",
    "y_pred = xgb.predict(x_validation)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_validation, y_pred))\n",
    "print(confusion_matrix(y_validation,y_pred))\n",
    "print(classification_report(y_validation,y_pred))\n",
    "\n",
    "#test\n",
    "y_pred_test = xgb.predict(x_validation_test)\n",
    "\n",
    "#normal 0.88 0.46"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "xgb=XGBClassifier()\n",
    "parameters = {\n",
    "    \"n_estimators\":[5,10,50,100,250],\n",
    "    \"max_depth\":[2,4,8,16,32,None]\n",
    "}\n",
    "cv = GridSearchCV(rfc,parameters,cv=5)\n",
    "cv.fit(x_train, y_train)\n",
    "\n",
    "#validation\n",
    "y_pred = cv.predict(x_validation)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_validation, y_pred))\n",
    "print(confusion_matrix(y_validation,y_pred))\n",
    "print(classification_report(y_validation,y_pred))\n",
    "\n",
    "#test\n",
    "y_pred_test = cv.predict(x_validation_test)\n",
    "\n",
    "#normal 0.89 0.47"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Random forest with most important feature selection\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create the RFE object and rank each\n",
    "clf_rf_3 = RandomForestClassifier(n_estimators=100,max_features='auto',random_state=0, max_depth=10)      \n",
    "rfe = RFE(estimator=clf_rf_3, n_features_to_select=21, step=1)\n",
    "rfe = rfe.fit(x_train, y_train)\n",
    "print('Chosen best features by rfe:',x_train.columns[rfe.support_])\n",
    "\n",
    "x_train_2 = rfe.transform(x_train)\n",
    "x_test_2 = rfe.transform(x_validation)\n",
    "\n",
    "#random forest classifier with n_estimators=10 (default)\n",
    "clf_rf_2 = RandomForestClassifier()      \n",
    "clr_rf_2 = clf_rf_2.fit(x_train_2,y_train)\n",
    "\n",
    "#validation\n",
    "y_pred=clf_rf_2.predict(x_test_2)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_validation, y_pred))\n",
    "print(confusion_matrix(y_validation,y_pred))\n",
    "print(classification_report(y_validation,y_pred))\n",
    "\n",
    "#test\n",
    "#y_pred_test = clf_rf_2.predict(x_validation_test)\n",
    "\n",
    "#normal 0.88 0.42"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Optimal number of features\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# The \"accuracy\" scoring is proportional to the number of correct classifications\n",
    "clf_rf_4 = RandomForestClassifier(n_estimators=100,max_features='auto',random_state=0, max_depth=10) \n",
    "rfecv = RFECV(estimator=clf_rf_4, step=1, cv=5,scoring='accuracy')   #5-fold cross-validation\n",
    "rfecv = rfecv.fit(x_train, y_train)\n",
    "\n",
    "print('Optimal number of features :', rfecv.n_features_)\n",
    "print('Best features :', x_train.columns[rfecv.support_])\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score of number of selected features\")\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "plt.show()\n",
    "\n",
    "#Optimal number of features : 17\n",
    "#Best features : Index(['0', '4', '5', '6', '7', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22'], dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=pd.DataFrame({'NEXT_MONTH_DEFAULT':y_pred_test})\n",
    "df_test.to_csv('Submissions/Submit3.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
