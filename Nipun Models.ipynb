{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Methods: Predicting Hotel Cancellations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.2\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import imblearn\n",
    "import matplotlib.pyplot as plt\n",
    "import mglearn\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data From AWS S3 to Sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import boto3\n",
    "# import botocore\n",
    "# from sagemaker import get_execution_role\n",
    "\n",
    "# role = get_execution_role()\n",
    "\n",
    "# bucket = 'enterbucketname'\n",
    "# data_key_train = 'H1full.csv'\n",
    "# data_location_train = 's3://{}/{}'.format(bucket, data_key_train)\n",
    "\n",
    "# train_df = pd.read_csv(data_location_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data Through CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('new_train_data_akeshala_nipun_samal_updated.csv')\n",
    "validation_df = pd.read_csv('new_validation_data_akeshala_nipun_samal_updated.csv')\n",
    "test_df = pd.read_csv('new_test_data_akeshala_nipun_samal_updated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=train_df.head()\n",
    "c = validation_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of        Unnamed: 0  Unnamed: 0.1  Reservation-id  Gender  Age  Ethnicity  \\\n",
       "0               0             0        39428300       1   40          1   \n",
       "1               1             1        77491756       1   49          1   \n",
       "2               2             2        73747291       1   42          2   \n",
       "3               3             3        67301739       2   25          3   \n",
       "4               4             4        77222321       1   62          1   \n",
       "...           ...           ...             ...     ...  ...        ...   \n",
       "26988       27494         27494        15645505       1   49          3   \n",
       "26989       27495         27495        56414525       1   49          4   \n",
       "26990       27496         27496        52023375       1   49          1   \n",
       "26991       27497         27497        98041387       2   65          3   \n",
       "26992       27498         27498        55243988       1   48          2   \n",
       "\n",
       "       Educational_Level  Income  Country_region  Hotel_Type  ...  Meal_Type  \\\n",
       "0                      4       1               1           1  ...          2   \n",
       "1                      2       3               2           1  ...          2   \n",
       "2                      4       1               2           1  ...          2   \n",
       "3                      1       4               3           3  ...          2   \n",
       "4                      3       2               2           2  ...          2   \n",
       "...                  ...     ...             ...         ...  ...        ...   \n",
       "26988                  2       1               4           1  ...          1   \n",
       "26989                  1       2               3           3  ...          2   \n",
       "26990                  3       3               3           3  ...          1   \n",
       "26991                  1       2               3           3  ...          3   \n",
       "26992                  1       2               1           2  ...          1   \n",
       "\n",
       "       Visted_Previously  Previous_Cancellations  Deposit_type  \\\n",
       "0                      0                       0             1   \n",
       "1                      0                       0             2   \n",
       "2                      0                       0             1   \n",
       "3                      0                       0             2   \n",
       "4                      0                       0             1   \n",
       "...                  ...                     ...           ...   \n",
       "26988                  1                       1             1   \n",
       "26989                  0                       0             2   \n",
       "26990                  0                       0             1   \n",
       "26991                  0                       0             1   \n",
       "26992                  0                       0             1   \n",
       "\n",
       "       Booking_channel  Required_Car_Parking  Reservation_Status  \\\n",
       "0                    2                     1                   2   \n",
       "1                    2                     1                   2   \n",
       "2                    2                     1                   2   \n",
       "3                    3                     1                   2   \n",
       "4                    1                     0                   2   \n",
       "...                ...                   ...                 ...   \n",
       "26988                2                     1                   2   \n",
       "26989                3                     1                   1   \n",
       "26990                1                     1                   2   \n",
       "26991                2                     0                   0   \n",
       "26992                2                     0                   1   \n",
       "\n",
       "       Use_Promotion  Discount_Rate  Room_Rate  \n",
       "0                  1             10        218  \n",
       "1                  0              0        185  \n",
       "2                  0              0        119  \n",
       "3                  1              5        144  \n",
       "4                  1             10        242  \n",
       "...              ...            ...        ...  \n",
       "26988              1             10        100  \n",
       "26989              1             40        194  \n",
       "26990              1              5        202  \n",
       "26991              1             20        157  \n",
       "26992              0              0        210  \n",
       "\n",
       "[26993 rows x 26 columns]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=train_df\n",
    "d = validation_df\n",
    "train_df.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#b.sort_values(['Income','Previous_Cancellations'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26993,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IsCanceled = train_df['Reservation_Status']\n",
    "y_train = IsCanceled\n",
    "y_validation = validation_df['Reservation_Status']\n",
    "y_val = y_validation.to_numpy()\n",
    "y_validation.shape\n",
    "# y_train.describe\n",
    "#y_val.reshape(2733,1)\n",
    "validation_df.shape\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gender = train_df['Gender']\n",
    "Age = train_df['Age']\n",
    "Ethnicity = train_df['Ethnicity']\n",
    "Educational_Level = train_df['Educational_Level']\n",
    "Income = train_df['Income']\n",
    "Country_region = train_df['Country_region']\n",
    "Hotel_Type = train_df['Hotel_Type']\n",
    "No_of_Expected_Days_to_stay = train_df['No_of_Expected_Days_to_stay']\n",
    "Checking_Month = train_df['Checking_Month']\n",
    "no_of_days_from_booking_to_ckeckin = train_df['no_of_days_from_booking_to_ckeckin']\n",
    "Meal_Type = train_df['Meal_Type']\n",
    "Visted_Previously = train_df['Visted_Previously']\n",
    "Deposit_type = train_df['Deposit_type']\n",
    "Booking_channel = train_df['Booking_channel']\n",
    "Required_Car_Parking = train_df['Required_Car_Parking']\n",
    "Use_Promotion = train_df['Use_Promotion']\n",
    "Discount_Rate = train_df['Discount_Rate']\n",
    "Room_Rate = train_df['Room_Rate']\n",
    "adults = train_df['Adults']\n",
    "children = train_df['Children']\n",
    "babies = train_df['Babies']\n",
    "previouscancellations = train_df['Previous_Cancellations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26993, 23)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.column_stack((Gender,Age,Ethnicity,Educational_Level,Income,Country_region,Hotel_Type,No_of_Expected_Days_to_stay,Checking_Month,Meal_Type,Visted_Previously,Deposit_type,Booking_channel,Required_Car_Parking,Use_Promotion,Discount_Rate,Room_Rate,adults,children,babies,previouscancellations,no_of_days_from_booking_to_ckeckin))\n",
    "x = sm.add_constant(x, prepend=True)\n",
    "x.shape\n",
    "# x = np.column_stack((Ethnicity,Educational_Level,Income,Country_region,Hotel_Type,No_of_Expected_Days_to_stay,Checking_Month,Meal_Type,Visted_Previously,Booking_channel,Required_Car_Parking,Discount_Rate,Room_Rate,adults,children,babies,no_of_days_from_booking_to_ckeckin))\n",
    "# x = sm.add_constant(x, prepend=True)\n",
    "# x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Numerical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gender_v = validation_df['Gender']\n",
    "Age_v = validation_df['Age']\n",
    "Ethnicity_v = validation_df['Ethnicity']\n",
    "Educational_Level_v = validation_df['Educational_Level']\n",
    "Income_v = validation_df['Income']\n",
    "Country_region_v = validation_df['Country_region']\n",
    "Hotel_Type_v = validation_df['Hotel_Type']\n",
    "No_of_Expected_Days_to_stay_v = validation_df['No_of_Expected_Days_to_stay']\n",
    "Checking_Month_v = validation_df['Checking_Month']\n",
    "no_of_days_from_booking_to_ckeckin_v = validation_df['no_of_days_from_booking_to_ckeckin']\n",
    "Meal_Type_v = validation_df['Meal_Type']\n",
    "Visted_Previously_v = validation_df['Visted_Previously']\n",
    "Deposit_type_v = validation_df['Deposit_type']\n",
    "Booking_channel_v = validation_df['Booking_channel']\n",
    "Required_Car_Parking_v = validation_df['Required_Car_Parking']\n",
    "Use_Promotion_v = validation_df['Use_Promotion']\n",
    "Discount_Rate_v = validation_df['Discount_Rate']\n",
    "Room_Rate_v = validation_df['Room_Rate']\n",
    "adults_v = validation_df['Adults']\n",
    "children_v = validation_df['Children']\n",
    "babies_v = validation_df['Babies']\n",
    "previouscancellations_v = validation_df['Previous_Cancellations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2733, 23)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_v = np.column_stack((Gender_v,Age_v,Ethnicity_v,Educational_Level_v,Income_v,Country_region_v,Hotel_Type_v,No_of_Expected_Days_to_stay_v,Checking_Month_v,Meal_Type_v,Visted_Previously_v,Deposit_type_v,Booking_channel_v,Required_Car_Parking_v,Use_Promotion_v,Discount_Rate_v,Room_Rate_v,adults_v,children_v,babies_v,previouscancellations_v,no_of_days_from_booking_to_ckeckin_v))\n",
    "x_v = sm.add_constant(x_v, prepend=True)\n",
    "x_v.shape\n",
    "# x_v = np.column_stack((Ethnicity_v,Educational_Level_v,Income_v,Country_region_v,Hotel_Type_v,No_of_Expected_Days_to_stay_v,Checking_Month_v,Meal_Type_v,Visted_Previously_v,Booking_channel_v,Required_Car_Parking_v,Discount_Rate_v,Room_Rate_v,adults_v,children_v,babies_v,no_of_days_from_booking_to_ckeckin_v))\n",
    "# x_v = sm.add_constant(x, prepend=True)\n",
    "# x_v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#under sample\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state = 23)\n",
    "x_train, y_train = rus.fit_sample(x, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapper-Based: Forward Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "xgb_model = xgb.XGBClassifier(learning_rate=0.01,\n",
    "                            max_depth =5, \n",
    "                            n_estimators = 1000,use_label_encoder=False,eval_metric = 'merror',min_child_weight = 4 )\n",
    "forward_feature_selector = SequentialFeatureSelector(xgb_model,\n",
    "           k_features=6,\n",
    "           forward=True,\n",
    "            verbose=2,\n",
    "           scoring='accuracy',\n",
    "            cv=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fselector = forward_feature_selector.fit(x,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fselector.k_feature_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "X_test = scaler.transform(x_v)\n",
    "classifier = RandomForestClassifier(n_estimators = 50, criterion = 'entropy', random_state = 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='entropy', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
       "                       n_jobs=None, oob_score=False, random_state=23, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    " y_predict = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.36      0.31       738\n",
      "           1       0.13      0.32      0.19       393\n",
      "           2       0.59      0.31      0.41      1602\n",
      "\n",
      "    accuracy                           0.33      2733\n",
      "   macro avg       0.33      0.33      0.30      2733\n",
      "weighted avg       0.44      0.33      0.35      2733\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "# print(confusion_matrix(y_validation,y_predict))\n",
    "print(classification_report(y_validation,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapper-Based: Backward Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "# from sklearn.metrics import roc_auc_score \n",
    "\n",
    "# backward_feature_selector = SequentialFeatureSelector(RandomForestClassifier(n_jobs=-1),\n",
    "#            k_features=6,\n",
    "#            forward=False,\n",
    "#            verbose=2,\n",
    "#            scoring='f1_macro',\n",
    "#            cv=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bselector = backward_feature_selector.fit(x, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.99621211 -1.57300494 ... -0.61879163 -0.34653285\n",
      "  -1.0614106 ]\n",
      " [ 0.          0.99621211  1.05259688 ... -0.61879163 -0.34653285\n",
      "   0.29831719]\n",
      " [ 0.          0.99621211 -0.91660449 ...  1.14631358 -0.34653285\n",
      "  -0.15969638]\n",
      " ...\n",
      " [ 0.          0.99621211  0.06799619 ... -0.61879163 -0.34653285\n",
      "   0.22675257]\n",
      " [ 0.         -1.0038023  -1.04788458 ...  1.14631358 -0.34653285\n",
      "  -0.47458071]\n",
      " [ 0.         -1.0038023   1.64335728 ...  1.14631358 -0.34653285\n",
      "  -1.31904323]]\n"
     ]
    }
   ],
   "source": [
    "#  bselector.k_feature_names_\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.0276514  0.06978126 0.04983222 0.05179565 0.05271344\n",
      " 0.05303995 0.04605162 0.04826914 0.06715753 0.04068549 0.02583636\n",
      " 0.034336   0.04162585 0.02781594 0.02006348 0.05213101 0.07104428\n",
      " 0.05355439 0.04467165 0.03100231 0.01241767 0.07852337]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>extratrees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.012418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.020063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.025836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.027816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.031002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.034336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.040685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.041626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.044672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.046052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.048269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.049832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.051796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.052131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.052713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.053040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.053554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.067158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.069781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.071044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.078523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    extratrees\n",
       "0     0.000000\n",
       "21    0.012418\n",
       "15    0.020063\n",
       "11    0.025836\n",
       "1     0.027651\n",
       "14    0.027816\n",
       "20    0.031002\n",
       "12    0.034336\n",
       "10    0.040685\n",
       "13    0.041626\n",
       "19    0.044672\n",
       "7     0.046052\n",
       "8     0.048269\n",
       "3     0.049832\n",
       "4     0.051796\n",
       "16    0.052131\n",
       "5     0.052713\n",
       "6     0.053040\n",
       "18    0.053554\n",
       "9     0.067158\n",
       "2     0.069781\n",
       "17    0.071044\n",
       "22    0.078523"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ext=pd.DataFrame(model.feature_importances_,columns=[\"extratrees\"])\n",
    "ext\n",
    "ext.sort_values(['extratrees'], ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selected Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1 = np.column_stack((leadtime,countrycat,marketsegmentcat,deposittypecat,customertypecat,rcps,arrivaldateweekno))\n",
    "# x1 = sm.add_constant(x1, prepend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1_train, x1_val, y1_train, y1_val = train_test_split(x1, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://stackoverflow.com/questions/52896387/svc-with-class-weight-in-scikit-learn\n",
    "# from sklearn import svm\n",
    "\n",
    "# clf = svm.LinearSVC(penalty='l2', loss='squared_hinge', dual=True, tol=0.001, C=2.0, multi_class='ovr', fit_intercept=True, intercept_scaling=1, class_weight=None, verbose=0, random_state=23, max_iter=10000)\n",
    "# clf.fit(x_train, y_train)  \n",
    "# prclf = clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report,confusion_matrix\n",
    "# print(confusion_matrix(y_val,prclf))\n",
    "# print(classification_report(y_val,prclf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(prclf))\n",
    "# print(type(y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xgboost as xgb\n",
    "# xgb_model = xgb.XGBClassifier(learning_rate=0.3,gamma=0.8,\n",
    "#                             max_depth =1, objective = 'multi:softmax',\n",
    "#                              n_estimators =50000,use_label_encoder=False,eval_metric = 'merror',min_child_weight = 6)\n",
    "\n",
    "# # xgb.XGBClassifier(learning_rate=0.1,\n",
    "# #                             max_depth = 2, \n",
    "# #                             n_estimators = 100,\n",
    "# #                               scale_pos_weight=3)\n",
    "# xgb_model.fit(x_train, y_train)\n",
    "\n",
    "# print(\"Accuracy on training set: {:.3f}\".format(xgb_model.score(x_train, y_train)))\n",
    "# print(\"Accuracy on validation set: {:.3f}\".format(xgb_model.score(X_test, y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_predict=xgb_model.predict(X_test)\n",
    "# xgb_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report,confusion_matrix\n",
    "# print(confusion_matrix(y_val,xgb_predict))\n",
    "# print(classification_report(y_val,xgb_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling for Naive Bayes and KNN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 2108, 1: 2108, 2: 2108})\n"
     ]
    }
   ],
   "source": [
    "counter = Counter(y_train)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversample = SMOTE()\n",
    "# x_train, y_train = oversample.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 2108, 1: 2108, 2: 2108})\n"
     ]
    }
   ],
   "source": [
    "counter = Counter(y_train)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 1, ..., 1, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = gnb.fit(x_train, y_train).predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[271 184 283]\n",
      " [142 113 138]\n",
      " [560 393 649]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.37      0.32       738\n",
      "           1       0.16      0.29      0.21       393\n",
      "           2       0.61      0.41      0.49      1602\n",
      "\n",
      "    accuracy                           0.38      2733\n",
      "   macro avg       0.35      0.35      0.34      2733\n",
      "weighted avg       0.45      0.38      0.40      2733\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(confusion_matrix(y_val,y_pred))\n",
    "print(classification_report(y_val,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN and SMOTE Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gender_t = test_df['Gender']\n",
    "Age_t = test_df['Age']\n",
    "Ethnicity_t = test_df['Ethnicity']\n",
    "Educational_Level_t = test_df['Educational_Level']\n",
    "Income_t = test_df['Income']\n",
    "Country_region_t = test_df['Country_region']\n",
    "Hotel_Type_t = test_df['Hotel_Type']\n",
    "No_of_Expected_Days_to_stay_t = test_df['No_of_Expected_Days_to_stay']\n",
    "Checking_Month_t = test_df['Checking_Month']\n",
    "no_of_days_from_booking_to_ckeckin_t = test_df['no_of_days_from_booking_to_ckeckin']\n",
    "Meal_Type_t = test_df['Meal_Type']\n",
    "Visted_Previously_t = test_df['Visted_Previously']\n",
    "Deposit_type_t = test_df['Deposit_type']\n",
    "Booking_channel_t = test_df['Booking_channel']\n",
    "Required_Car_Parking_t = test_df['Required_Car_Parking']\n",
    "Use_Promotion_t = test_df['Use_Promotion']\n",
    "Discount_Rate_t = test_df['Discount_Rate']\n",
    "Room_Rate_t = test_df['Room_Rate']\n",
    "adults_t = test_df['Adults']\n",
    "children_t = test_df['Children']\n",
    "babies_t = test_df['Babies']\n",
    "previouscancellations_t = test_df['Previous_Cancellations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt = np.column_stack((Gender_t,Age_t,Ethnicity_t,Educational_Level_t,Income_t,Country_region_t,Hotel_Type_t,No_of_Expected_Days_to_stay_t,Checking_Month_t,Meal_Type_t,Visted_Previously_t,Deposit_type_t,Booking_channel_t,Required_Car_Parking_t,Use_Promotion_t,Discount_Rate_t,Room_Rate_t,adults_t,children_t,babies_t,previouscancellations_t,no_of_days_from_booking_to_ckeckin_t))\n",
    "xt = sm.add_constant(xt, prepend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_testt = scaler.transform(xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, ..., 2, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = gnb.fit(x_train, y_train).predict(xt)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"foo.csv\", y_pred, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train = MinMaxScaler().fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "knn=knn.fit(x1_train, y_train)\n",
    "pred = knn.predict(X_test)\n",
    "pred\n",
    "print(\"Training set score: {:.2f}\".format(knn.score(x1_train, y_train)))\n",
    "print(\"Validation set score: {:.2f}\".format(knn.score(X_test, y_val)))\n",
    "\n",
    "# KNN Plot\n",
    "mglearn.plots.plot_knn_classification(n_neighbors=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(confusion_matrix(y_val,pred))\n",
    "print(classification_report(y_val,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data using SVM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data from AWS S3 to SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_key_test = 'H2full.csv'\n",
    "# data_location_test = 's3://{}/{}'.format(bucket, data_key_test)\n",
    "\n",
    "# h2data = pd.read_csv(data_location_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2data = pd.read_csv('H2.csv')\n",
    "a=h2data.head()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(h2data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_leadtime = h2data['LeadTime'] #1\n",
    "t_arrivaldateyear = h2data['ArrivalDateYear']\n",
    "t_arrivaldateweekno = h2data['ArrivalDateWeekNumber']\n",
    "t_arrivaldatedayofmonth = h2data['ArrivalDateDayOfMonth']\n",
    "t_staysweekendnights = h2data['StaysInWeekendNights'] #2\n",
    "t_staysweeknights = h2data['StaysInWeekNights'] #3\n",
    "t_adults = h2data['Adults'] #4\n",
    "t_children = h2data['Children'] #5\n",
    "t_babies = h2data['Babies'] #6\n",
    "t_previouscancellations = h2data['PreviousCancellations'] #12\n",
    "t_previousbookingsnotcanceled = h2data['PreviousBookingsNotCanceled'] #13\n",
    "t_bookingchanges = h2data['BookingChanges'] #16\n",
    "t_dayswaitinglist = h2data['DaysInWaitingList'] #20\n",
    "t_adr = h2data['ADR'] #22\n",
    "t_rcps = h2data['RequiredCarParkingSpaces'] #23\n",
    "t_totalsqr = h2data['TotalOfSpecialRequests'] #24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_arrivaldatemonth = h2data.ArrivalDateMonth.astype(\"category\").cat.codes\n",
    "t_arrivaldatemonthcat = pd.Series(t_arrivaldatemonth)\n",
    "t_mealcat=h2data.Meal.astype(\"category\").cat.codes\n",
    "t_mealcat=pd.Series(t_mealcat)\n",
    "t_countrycat=h2data.Country.astype(\"category\").cat.codes\n",
    "t_countrycat=pd.Series(t_countrycat)\n",
    "t_marketsegmentcat=h2data.MarketSegment.astype(\"category\").cat.codes\n",
    "t_marketsegmentcat=pd.Series(t_marketsegmentcat)\n",
    "t_distributionchannelcat=h2data.DistributionChannel.astype(\"category\").cat.codes\n",
    "t_distributionchannelcat=pd.Series(t_distributionchannelcat)\n",
    "t_reservedroomtypecat=h2data.ReservedRoomType.astype(\"category\").cat.codes\n",
    "t_reservedroomtypecat=pd.Series(t_reservedroomtypecat)\n",
    "t_assignedroomtypecat=h2data.AssignedRoomType.astype(\"category\").cat.codes\n",
    "t_assignedroomtypecat=pd.Series(t_assignedroomtypecat)\n",
    "t_deposittypecat=h2data.DepositType.astype(\"category\").cat.codes\n",
    "t_deposittypecat=pd.Series(t_deposittypecat)\n",
    "t_customertypecat=h2data.CustomerType.astype(\"category\").cat.codes\n",
    "t_customertypecat=pd.Series(t_customertypecat)\n",
    "t_reservationstatuscat=h2data.ReservationStatus.astype(\"category\").cat.codes\n",
    "t_reservationstatuscat=pd.Series(t_reservationstatuscat)\n",
    "t_isrepeatedguestcat = h2data.IsRepeatedGuest.astype(\"category\").cat.codes\n",
    "t_isrepeatedguestcat=pd.Series(t_isrepeatedguestcat)\n",
    "t_agentcat = h2data.Agent.astype(\"category\").cat.codes\n",
    "t_agentcat=pd.Series(t_agentcat)\n",
    "t_companycat = h2data.Company.astype(\"category\").cat.codes\n",
    "t_companycat=pd.Series(t_companycat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.column_stack((t_leadtime,t_countrycat,t_marketsegmentcat,t_deposittypecat,t_customertypecat,t_rcps,t_arrivaldateweekno))\n",
    "a = sm.add_constant(a, prepend=True)\n",
    "IsCanceled = h2data['IsCanceled']\n",
    "b = IsCanceled\n",
    "b=b.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prh2 = clf.predict(a)\n",
    "prh2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(confusion_matrix(b,prh2))\n",
    "print(classification_report(b,prh2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
