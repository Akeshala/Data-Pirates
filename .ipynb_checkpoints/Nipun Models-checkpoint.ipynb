{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Methods: Predicting Hotel Cancellations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.2\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import imblearn\n",
    "import matplotlib.pyplot as plt\n",
    "import mglearn\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data From AWS S3 to Sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import boto3\n",
    "# import botocore\n",
    "# from sagemaker import get_execution_role\n",
    "\n",
    "# role = get_execution_role()\n",
    "\n",
    "# bucket = 'enterbucketname'\n",
    "# data_key_train = 'H1full.csv'\n",
    "# data_location_train = 's3://{}/{}'.format(bucket, data_key_train)\n",
    "\n",
    "# train_df = pd.read_csv(data_location_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data Through CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('new_train_data_akeshala_nipun_samal.csv')\n",
    "validation_df = pd.read_csv('new_validation_data_akeshala_nipun_samal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=train_df.head()\n",
    "c = validation_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of        Unnamed: 0  Reservation-id  Gender  Age  Ethnicity  Educational_Level  \\\n",
       "0               0        39428300       1   40          1                  4   \n",
       "1               1        77491756       1   49          1                  2   \n",
       "2               2        73747291       1   42          2                  4   \n",
       "3               3        67301739       2   25          3                  1   \n",
       "4               4        77222321       1   62          1                  3   \n",
       "...           ...             ...     ...  ...        ...                ...   \n",
       "27494       27494        15645505       1   49          3                  2   \n",
       "27495       27495        56414525       1   49          4                  1   \n",
       "27496       27496        52023375       1   49          1                  3   \n",
       "27497       27497        98041387       2   65          3                  1   \n",
       "27498       27498        55243988       1   48          2                  1   \n",
       "\n",
       "       Income  Country_region  Hotel_Type  No_of_Expected_Days_to_stay  ...  \\\n",
       "0           1               1           1                            1  ...   \n",
       "1           3               2           1                            1  ...   \n",
       "2           1               2           1                            4  ...   \n",
       "3           4               3           3                            1  ...   \n",
       "4           2               2           2                            1  ...   \n",
       "...       ...             ...         ...                          ...  ...   \n",
       "27494       1               4           1                            1  ...   \n",
       "27495       2               3           3                            1  ...   \n",
       "27496       3               3           3                            1  ...   \n",
       "27497       2               3           3                            1  ...   \n",
       "27498       2               1           2                            1  ...   \n",
       "\n",
       "       Meal_Type  Visted_Previously  Previous_Cancellations  Deposit_type  \\\n",
       "0              1                  0                       0             0   \n",
       "1              1                  0                       0             1   \n",
       "2              1                  0                       0             0   \n",
       "3              1                  0                       0             1   \n",
       "4              1                  0                       0             0   \n",
       "...          ...                ...                     ...           ...   \n",
       "27494          0                  1                       1             0   \n",
       "27495          1                  0                       0             1   \n",
       "27496          0                  0                       0             0   \n",
       "27497          2                  0                       0             0   \n",
       "27498          0                  0                       0             0   \n",
       "\n",
       "       Booking_channel  Required_Car_Parking  Reservation_Status  \\\n",
       "0                    1                     1                   2   \n",
       "1                    1                     1                   2   \n",
       "2                    1                     1                   2   \n",
       "3                    2                     1                   2   \n",
       "4                    0                     0                   2   \n",
       "...                ...                   ...                 ...   \n",
       "27494                1                     1                   2   \n",
       "27495                2                     1                   1   \n",
       "27496                0                     1                   2   \n",
       "27497                1                     0                   0   \n",
       "27498                1                     0                   1   \n",
       "\n",
       "       Use_Promotion  Discount_Rate  Room_Rate  \n",
       "0                  1             10        218  \n",
       "1                  0              0        185  \n",
       "2                  0              0        119  \n",
       "3                  1              5        144  \n",
       "4                  1             10        242  \n",
       "...              ...            ...        ...  \n",
       "27494              1             10        100  \n",
       "27495              1             40        194  \n",
       "27496              1              5        202  \n",
       "27497              1             20        157  \n",
       "27498              0              0        210  \n",
       "\n",
       "[27499 rows x 25 columns]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=train_df\n",
    "d = validation_df\n",
    "train_df.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#b.sort_values(['Income','Previous_Cancellations'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27499,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IsCanceled = train_df['Reservation_Status']\n",
    "y_train = IsCanceled\n",
    "y_validation = validation_df['Reservation_Status']\n",
    "y_val = y_validation.to_numpy()\n",
    "y_validation.shape\n",
    "# y_train.describe\n",
    "y_val.reshape(2749,1)\n",
    "validation_df.shape\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gender = train_df['Gender']\n",
    "Age = train_df['Age']\n",
    "Ethnicity = train_df['Ethnicity']\n",
    "Educational_Level = train_df['Educational_Level']\n",
    "Income = train_df['Income']\n",
    "Country_region = train_df['Country_region']\n",
    "Hotel_Type = train_df['Hotel_Type']\n",
    "No_of_Expected_Days_to_stay = train_df['No_of_Expected_Days_to_stay']\n",
    "Checking_Month = train_df['Checking_Month']\n",
    "no_of_days_from_booking_to_ckeckin = train_df['no_of_days_from_booking_to_ckeckin']\n",
    "Meal_Type = train_df['Meal_Type']\n",
    "Visted_Previously = train_df['Visted_Previously']\n",
    "Deposit_type = train_df['Deposit_type']\n",
    "Booking_channel = train_df['Booking_channel']\n",
    "Required_Car_Parking = train_df['Required_Car_Parking']\n",
    "Use_Promotion = train_df['Use_Promotion']\n",
    "Discount_Rate = train_df['Discount_Rate']\n",
    "Room_Rate = train_df['Room_Rate']\n",
    "adults = train_df['Adults']\n",
    "children = train_df['Children']\n",
    "babies = train_df['Babies']\n",
    "previouscancellations = train_df['Previous_Cancellations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27499, 23)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.column_stack((Gender,Age,Ethnicity,Educational_Level,Income,Country_region,Hotel_Type,No_of_Expected_Days_to_stay,Checking_Month,no_of_days_from_booking_to_ckeckin,Meal_Type,Visted_Previously,Deposit_type,Booking_channel,Required_Car_Parking,Use_Promotion,Discount_Rate,Room_Rate,adults,children,babies,previouscancellations))\n",
    "x = sm.add_constant(x, prepend=True)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Numerical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gender_v = validation_df['Gender']\n",
    "Gender_v.shape\n",
    "Age_v = validation_df['Age']\n",
    "Ethnicity_v = validation_df['Ethnicity']\n",
    "Educational_Level_v = validation_df['Educational_Level']\n",
    "Income_v = validation_df['Income']\n",
    "Country_region_v = validation_df['Country_region']\n",
    "Hotel_Type_v = validation_df['Hotel_Type']\n",
    "No_of_Expected_Days_to_stay_v = validation_df['No_of_Expected_Days_to_stay']\n",
    "Checking_Month_v = validation_df['Checking_Month']\n",
    "no_of_days_from_booking_to_ckeckin_v = validation_df['no_of_days_from_booking_to_ckeckin']\n",
    "Meal_Type_v = validation_df['Meal_Type']\n",
    "Visted_Previously_v = validation_df['Visted_Previously']\n",
    "Deposit_type_v = validation_df['Deposit_type']\n",
    "Booking_channel_v = validation_df['Booking_channel']\n",
    "Required_Car_Parking_v = validation_df['Required_Car_Parking']\n",
    "Use_Promotion_v = validation_df['Use_Promotion']\n",
    "Discount_Rate_v = validation_df['Discount_Rate']\n",
    "Room_Rate_v = validation_df['Room_Rate']\n",
    "adults_v = validation_df['Adults']\n",
    "children_v = validation_df['Children']\n",
    "babies_v = validation_df['Babies']\n",
    "previouscancellations_v = validation_df['Previous_Cancellations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2749, 23)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_v = np.column_stack((Gender_v,Age_v,Ethnicity_v,Educational_Level_v,Income_v,Country_region_v,Hotel_Type_v,No_of_Expected_Days_to_stay_v,Checking_Month_v,no_of_days_from_booking_to_ckeckin_v,Meal_Type_v,Visted_Previously_v,Deposit_type_v,Booking_channel_v,Required_Car_Parking_v,Use_Promotion_v,Discount_Rate_v,Room_Rate_v,adults_v,children_v,babies_v,previouscancellations_v))\n",
    "x_v = sm.add_constant(x_v, prepend=True)\n",
    "x_v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapper-Based: Forward Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "xgb_model = xgb.XGBClassifier(learning_rate=0.01,\n",
    "                            max_depth =5, \n",
    "                            n_estimators = 1000,use_label_encoder=False,eval_metric = 'merror',min_child_weight = 4 )\n",
    "forward_feature_selector = SequentialFeatureSelector(xgb_model,\n",
    "           k_features=6,\n",
    "           forward=True,\n",
    "            verbose=2,\n",
    "           scoring='accuracy',\n",
    "            cv=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   34.1s remaining:    0.0s\n"
     ]
    }
   ],
   "source": [
    "fselector = forward_feature_selector.fit(x,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fselector.k_feature_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(x)\n",
    "# X_test = scaler.transform(x_v)\n",
    "# classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier.fit(x, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_predict = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report,confusion_matrix\n",
    "# # print(confusion_matrix(y_validation,y_predict))\n",
    "# print(classification_report(y_validation,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapper-Based: Backward Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score \n",
    "\n",
    "backward_feature_selector = SequentialFeatureSelector(RandomForestClassifier(n_jobs=-1),\n",
    "           k_features=6,\n",
    "           forward=False,\n",
    "           verbose=2,\n",
    "           scoring='f1_macro',\n",
    "           cv=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   11.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  23 out of  23 | elapsed:  3.7min finished\n",
      "\n",
      "[2021-03-13 14:09:57] Features: 22/6 -- score: 0.29399276887106807[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    9.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed:  3.5min finished\n",
      "\n",
      "[2021-03-13 14:13:26] Features: 21/6 -- score: 0.2972764888054109[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    8.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:  3.1min finished\n",
      "\n",
      "[2021-03-13 14:16:31] Features: 20/6 -- score: 0.2961443458290681[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:  3.4min finished\n",
      "\n",
      "[2021-03-13 14:19:57] Features: 19/6 -- score: 0.29793878397771545[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    9.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed:  2.6min finished\n",
      "\n",
      "[2021-03-13 14:22:34] Features: 18/6 -- score: 0.30047830578338575[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    8.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:  2.6min finished\n",
      "\n",
      "[2021-03-13 14:25:10] Features: 17/6 -- score: 0.302352796796034[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   10.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed:  2.6min finished\n",
      "\n",
      "[2021-03-13 14:27:45] Features: 16/6 -- score: 0.30691550705991505[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:  2.0min finished\n",
      "\n",
      "[2021-03-13 14:29:44] Features: 15/6 -- score: 0.3163737584314023[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:  1.7min finished\n",
      "\n",
      "[2021-03-13 14:31:27] Features: 14/6 -- score: 0.32866243046198235[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed:  1.5min finished\n",
      "\n",
      "[2021-03-13 14:32:55] Features: 13/6 -- score: 0.33700304677466525[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:  1.4min finished\n",
      "\n",
      "[2021-03-13 14:34:21] Features: 12/6 -- score: 0.3370786853723225[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:  1.1min finished\n",
      "\n",
      "[2021-03-13 14:35:30] Features: 11/6 -- score: 0.3357383678067675[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:   55.4s finished\n",
      "\n",
      "[2021-03-13 14:36:26] Features: 10/6 -- score: 0.33835678444884143[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   45.6s finished\n",
      "\n",
      "[2021-03-13 14:37:11] Features: 9/6 -- score: 0.3371969474911142[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   37.4s finished\n",
      "\n",
      "[2021-03-13 14:37:49] Features: 8/6 -- score: 0.33486443460745374[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   28.5s finished\n",
      "\n",
      "[2021-03-13 14:38:17] Features: 7/6 -- score: 0.3211790248928221[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   21.5s finished\n",
      "\n",
      "[2021-03-13 14:38:39] Features: 6/6 -- score: 0.30860256273357367"
     ]
    }
   ],
   "source": [
    "bselector = backward_feature_selector.fit(x, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('5', '7', '8', '11', '14', '20')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " bselector.k_feature_names_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.0264368  0.07429667 0.05208193 0.05025483 0.05316777\n",
      " 0.05205331 0.04033748 0.04954516 0.06702389 0.07852805 0.04571274\n",
      " 0.02138131 0.03223112 0.04308392 0.02623265 0.01811955 0.05481758\n",
      " 0.07576989 0.05443014 0.04062771 0.03287023 0.01099727]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(x, y_train)\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>extratrees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.010997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.018120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.021381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.026233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.026437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.032231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.032870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.040337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.040628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.043084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.045713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.049545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.050255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.052053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.052082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.053168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.054430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.054818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.067024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.074297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.075770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.078528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    extratrees\n",
       "0     0.000000\n",
       "22    0.010997\n",
       "16    0.018120\n",
       "12    0.021381\n",
       "15    0.026233\n",
       "1     0.026437\n",
       "13    0.032231\n",
       "21    0.032870\n",
       "7     0.040337\n",
       "20    0.040628\n",
       "14    0.043084\n",
       "11    0.045713\n",
       "8     0.049545\n",
       "4     0.050255\n",
       "6     0.052053\n",
       "3     0.052082\n",
       "5     0.053168\n",
       "19    0.054430\n",
       "17    0.054818\n",
       "9     0.067024\n",
       "2     0.074297\n",
       "18    0.075770\n",
       "10    0.078528"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ext=pd.DataFrame(model.feature_importances_,columns=[\"extratrees\"])\n",
    "ext\n",
    "ext.sort_values(['extratrees'], ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selected Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1 = np.column_stack((leadtime,countrycat,marketsegmentcat,deposittypecat,customertypecat,rcps,arrivaldateweekno))\n",
    "# x1 = sm.add_constant(x1, prepend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1_train, x1_val, y1_train, y1_val = train_test_split(x1, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-b6e9c18e918c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinearSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'l2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'squared_hinge'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdual\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_class\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ovr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_intercept\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mintercept_scaling\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/52896387/svc-with-class-weight-in-scikit-learn\n",
    "from sklearn import svm\n",
    "\n",
    "clf = svm.LinearSVC(penalty='l2', loss='squared_hinge', dual=True, tol=0.0001, C=1.0, multi_class='ovr', fit_intercept=True, intercept_scaling=1, class_weight=None, verbose=0, random_state=None, max_iter=5000)\n",
    "clf.fit(X_train, y_train)  \n",
    "prclf = clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(confusion_matrix(y_val,prclf))\n",
    "print(classification_report(y_val,prclf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(prclf))\n",
    "print(type(y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "xgb_model = xgb.XGBClassifier(learning_rate=0.01,\n",
    "                            max_depth =5, \n",
    "                            n_estimators = 1000,use_label_encoder=False,eval_metric = 'merror',min_child_weight = 4 )\n",
    "xgb_model.fit(x, y_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.3f}\".format(xgb_model.score(x, y_train)))\n",
    "print(\"Accuracy on validation set: {:.3f}\".format(xgb_model.score(x_v, y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predict=xgb_model.predict(X_test)\n",
    "xgb_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(confusion_matrix(y_val,xgb_predict))\n",
    "print(classification_report(y_val,xgb_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling for Naive Bayes and KNN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(y_train)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE()\n",
    "X_train, y_train = oversample.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(y_train)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(confusion_matrix(y_val,y_pred))\n",
    "print(classification_report(y_val,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN and SMOTE Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train = MinMaxScaler().fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "knn=knn.fit(x1_train, y_train)\n",
    "pred = knn.predict(X_test)\n",
    "pred\n",
    "print(\"Training set score: {:.2f}\".format(knn.score(x1_train, y_train)))\n",
    "print(\"Validation set score: {:.2f}\".format(knn.score(X_test, y_val)))\n",
    "\n",
    "# KNN Plot\n",
    "mglearn.plots.plot_knn_classification(n_neighbors=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(confusion_matrix(y_val,pred))\n",
    "print(classification_report(y_val,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data using SVM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data from AWS S3 to SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_key_test = 'H2full.csv'\n",
    "# data_location_test = 's3://{}/{}'.format(bucket, data_key_test)\n",
    "\n",
    "# h2data = pd.read_csv(data_location_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2data = pd.read_csv('H2.csv')\n",
    "a=h2data.head()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(h2data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_leadtime = h2data['LeadTime'] #1\n",
    "t_arrivaldateyear = h2data['ArrivalDateYear']\n",
    "t_arrivaldateweekno = h2data['ArrivalDateWeekNumber']\n",
    "t_arrivaldatedayofmonth = h2data['ArrivalDateDayOfMonth']\n",
    "t_staysweekendnights = h2data['StaysInWeekendNights'] #2\n",
    "t_staysweeknights = h2data['StaysInWeekNights'] #3\n",
    "t_adults = h2data['Adults'] #4\n",
    "t_children = h2data['Children'] #5\n",
    "t_babies = h2data['Babies'] #6\n",
    "t_previouscancellations = h2data['PreviousCancellations'] #12\n",
    "t_previousbookingsnotcanceled = h2data['PreviousBookingsNotCanceled'] #13\n",
    "t_bookingchanges = h2data['BookingChanges'] #16\n",
    "t_dayswaitinglist = h2data['DaysInWaitingList'] #20\n",
    "t_adr = h2data['ADR'] #22\n",
    "t_rcps = h2data['RequiredCarParkingSpaces'] #23\n",
    "t_totalsqr = h2data['TotalOfSpecialRequests'] #24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_arrivaldatemonth = h2data.ArrivalDateMonth.astype(\"category\").cat.codes\n",
    "t_arrivaldatemonthcat = pd.Series(t_arrivaldatemonth)\n",
    "t_mealcat=h2data.Meal.astype(\"category\").cat.codes\n",
    "t_mealcat=pd.Series(t_mealcat)\n",
    "t_countrycat=h2data.Country.astype(\"category\").cat.codes\n",
    "t_countrycat=pd.Series(t_countrycat)\n",
    "t_marketsegmentcat=h2data.MarketSegment.astype(\"category\").cat.codes\n",
    "t_marketsegmentcat=pd.Series(t_marketsegmentcat)\n",
    "t_distributionchannelcat=h2data.DistributionChannel.astype(\"category\").cat.codes\n",
    "t_distributionchannelcat=pd.Series(t_distributionchannelcat)\n",
    "t_reservedroomtypecat=h2data.ReservedRoomType.astype(\"category\").cat.codes\n",
    "t_reservedroomtypecat=pd.Series(t_reservedroomtypecat)\n",
    "t_assignedroomtypecat=h2data.AssignedRoomType.astype(\"category\").cat.codes\n",
    "t_assignedroomtypecat=pd.Series(t_assignedroomtypecat)\n",
    "t_deposittypecat=h2data.DepositType.astype(\"category\").cat.codes\n",
    "t_deposittypecat=pd.Series(t_deposittypecat)\n",
    "t_customertypecat=h2data.CustomerType.astype(\"category\").cat.codes\n",
    "t_customertypecat=pd.Series(t_customertypecat)\n",
    "t_reservationstatuscat=h2data.ReservationStatus.astype(\"category\").cat.codes\n",
    "t_reservationstatuscat=pd.Series(t_reservationstatuscat)\n",
    "t_isrepeatedguestcat = h2data.IsRepeatedGuest.astype(\"category\").cat.codes\n",
    "t_isrepeatedguestcat=pd.Series(t_isrepeatedguestcat)\n",
    "t_agentcat = h2data.Agent.astype(\"category\").cat.codes\n",
    "t_agentcat=pd.Series(t_agentcat)\n",
    "t_companycat = h2data.Company.astype(\"category\").cat.codes\n",
    "t_companycat=pd.Series(t_companycat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.column_stack((t_leadtime,t_countrycat,t_marketsegmentcat,t_deposittypecat,t_customertypecat,t_rcps,t_arrivaldateweekno))\n",
    "a = sm.add_constant(a, prepend=True)\n",
    "IsCanceled = h2data['IsCanceled']\n",
    "b = IsCanceled\n",
    "b=b.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prh2 = clf.predict(a)\n",
    "prh2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(confusion_matrix(b,prh2))\n",
    "print(classification_report(b,prh2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
