{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from numpy.random import seed\n",
    "seed(2)\n",
    "df = pd.read_csv('credit_card_default_train.csv', header=0)\n",
    "df_test = pd.read_csv('credit_card_default_test.csv', header=0)\n",
    "#features=list(df.columns[:])\n",
    "#features\n",
    "#X.isnull().sum() check whether some values are missing"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# ['Client_ID', \n",
    " 'Balance_Limit_V1',\n",
    " 'Gender',\n",
    " 'EDUCATION_STATUS',\n",
    " 'MARITAL_STATUS',\n",
    " 'AGE',\n",
    " 'PAY_JULY',\n",
    " 'PAY_AUG',\n",
    " 'PAY_SEP',\n",
    " 'PAY_OCT',\n",
    " 'PAY_NOV',\n",
    " 'PAY_DEC',\n",
    " 'DUE_AMT_JULY',\n",
    " 'DUE_AMT_AUG',\n",
    " 'DUE_AMT_SEP',\n",
    " 'DUE_AMT_OCT',\n",
    " 'DUE_AMT_NOV',\n",
    " 'DUE_AMT_DEC',\n",
    " 'PAID_AMT_JULY',\n",
    " 'PAID_AMT_AUG',\n",
    " 'PAID_AMT_SEP',\n",
    " 'PAID_AMT_OCT',\n",
    " 'PAID_AMT_NOV',\n",
    " 'PAID_AMT_DEC',\n",
    " 'NEXT_MONTH_DEFAULT']\n",
    "\n",
    "['Client_ID',\n",
    " 'Balance_Limit_V1', 0\n",
    " 'Gender',           1\n",
    " 'EDUCATION_STATUS', 2\n",
    " 'MARITAL_STATUS',   3\n",
    " 'AGE',              4\n",
    " 'PAY_JULY',         5\n",
    " 'PAY_AUG',          6\n",
    " 'PAY_SEP',          7\n",
    " 'PAY_OCT',          8\n",
    " 'PAY_NOV',          9\n",
    " 'PAY_DEC',          10\n",
    " 'DUE_AMT_JULY',     11\n",
    " 'DUE_AMT_AUG',      12\n",
    " 'DUE_AMT_SEP',      13\n",
    " 'DUE_AMT_OCT',      14\n",
    " 'DUE_AMT_NOV',      15\n",
    " 'DUE_AMT_DEC',      16\n",
    " 'PAID_AMT_JULY',    17\n",
    " 'PAID_AMT_AUG',     18\n",
    " 'PAID_AMT_SEP',     19\n",
    " 'PAID_AMT_OCT',     20\n",
    " 'PAID_AMT_NOV',     21\n",
    " 'PAID_AMT_DEC',     22\n",
    " 'NEXT_MONTH_DEFAULT'] 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,1:24]\n",
    "y=df.iloc[:,24:25]\n",
    "X_test=df_test.iloc[:,1:24]\n",
    "y_test=df_test.iloc[:,24:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1=X.iloc[:,0:1]\n",
    "X2=X.iloc[:,1:2]\n",
    "X3=X.iloc[:,2:3]\n",
    "X4=X.iloc[:,3:4]\n",
    "X5=X.iloc[:,4:5]\n",
    "X6=X.iloc[:,5:6]\n",
    "X7=X.iloc[:,6:7]\n",
    "X8=X.iloc[:,7:8]\n",
    "X9=X.iloc[:,8:9]\n",
    "X10=X.iloc[:,9:10]\n",
    "X11=X.iloc[:,10:11]\n",
    "X12=X.iloc[:,11:12]\n",
    "X13=X.iloc[:,12:13]\n",
    "X14=X.iloc[:,13:14]\n",
    "X15=X.iloc[:,14:15]\n",
    "X16=X.iloc[:,15:16]\n",
    "X17=X.iloc[:,16:17]\n",
    "X18=X.iloc[:,17:18]\n",
    "X19=X.iloc[:,18:19]\n",
    "X20=X.iloc[:,19:20]\n",
    "X21=X.iloc[:,20:21]\n",
    "X22=X.iloc[:,21:22]\n",
    "X23=X.iloc[:,22:23]\n",
    "\n",
    "X1_test=X_test.iloc[:,0:1]\n",
    "X2_test=X_test.iloc[:,1:2]\n",
    "X3_test=X_test.iloc[:,2:3]\n",
    "X4_test=X_test.iloc[:,3:4]\n",
    "X5_test=X_test.iloc[:,4:5]\n",
    "X6_test=X_test.iloc[:,5:6]\n",
    "X7_test=X_test.iloc[:,6:7]\n",
    "X8_test=X_test.iloc[:,7:8]\n",
    "X9_test=X_test.iloc[:,8:9]\n",
    "X10_test=X_test.iloc[:,9:10]\n",
    "X11_test=X_test.iloc[:,10:11]\n",
    "X12_test=X_test.iloc[:,11:12]\n",
    "X13_test=X_test.iloc[:,12:13]\n",
    "X14_test=X_test.iloc[:,13:14]\n",
    "X15_test=X_test.iloc[:,14:15]\n",
    "X16_test=X_test.iloc[:,15:16]\n",
    "X17_test=X_test.iloc[:,16:17]\n",
    "X18_test=X_test.iloc[:,17:18]\n",
    "X19_test=X_test.iloc[:,18:19]\n",
    "X20_test=X_test.iloc[:,19:20]\n",
    "X21_test=X_test.iloc[:,20:21]\n",
    "X22_test=X_test.iloc[:,21:22]\n",
    "X23_test=X_test.iloc[:,22:23]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#train\n",
    "#X1\n",
    "values = array(X1)\n",
    "label_encoder = LabelEncoder()\n",
    "X1 = label_encoder.fit_transform(values)\n",
    "X1=pd.DataFrame(X1, columns=['Balance_Limit_V1'])\n",
    "#values_mappings = {index: label for index, label in enumerate(label_encoder.classes_)}\n",
    "#print(values_mappings)\n",
    "\n",
    "#X2\n",
    "values = array(X2)\n",
    "label_encoder = LabelEncoder()\n",
    "X2 = label_encoder.fit_transform(values)\n",
    "X2=pd.DataFrame(X2, columns=['Gender'])\n",
    "#values_mappings = {index: label for index, label in enumerate(label_encoder.classes_)}\n",
    "#print(values_mappings)\n",
    "\n",
    "#X3\n",
    "values = array(X3)\n",
    "label_encoder = LabelEncoder()\n",
    "X3 = label_encoder.fit_transform(values)\n",
    "X3=pd.DataFrame(X3, columns=['EDUCATION_STATUS'])\n",
    "#values_mappings = {index: label for index, label in enumerate(label_encoder.classes_)}\n",
    "#print(values_mappings)\n",
    "\n",
    "#X4\n",
    "values = array(X4)\n",
    "label_encoder = LabelEncoder()\n",
    "X4 = label_encoder.fit_transform(values)\n",
    "X4=pd.DataFrame(X4, columns=['MARITAL_STATUS'])\n",
    "#values_mappings = {index: label for index, label in enumerate(label_encoder.classes_)}\n",
    "#print(values_mappings)\n",
    "\n",
    "#X5\n",
    "values = array(X5)\n",
    "label_encoder = LabelEncoder()\n",
    "X5 = label_encoder.fit_transform(values)\n",
    "X5=pd.DataFrame(X5, columns=['AGE'])\n",
    "#values_mappings = {index: label for index, label in enumerate(label_encoder.classes_)}\n",
    "#print(values_mappings)\n",
    "\n",
    "#train end\n",
    "\n",
    "\n",
    "\n",
    "#test\n",
    "#X1\n",
    "values = array(X1_test)\n",
    "label_encoder = LabelEncoder()\n",
    "X1_test = label_encoder.fit_transform(values)\n",
    "X1_test=pd.DataFrame(X1_test, columns=['Balance_Limit_V1'])\n",
    "\n",
    "#X2\n",
    "values = array(X2_test)\n",
    "label_encoder = LabelEncoder()\n",
    "X2_test = label_encoder.fit_transform(values)\n",
    "X2_test=pd.DataFrame(X2_test, columns=['Gender'])\n",
    "\n",
    "#X3\n",
    "values = array(X3_test)\n",
    "label_encoder = LabelEncoder()\n",
    "X3_test = label_encoder.fit_transform(values)\n",
    "X3_test=pd.DataFrame(X3_test, columns=['EDUCATION_STATUS'])\n",
    "\n",
    "#X4\n",
    "values = array(X4_test)\n",
    "label_encoder = LabelEncoder()\n",
    "X4_test = label_encoder.fit_transform(values)\n",
    "X4_test=pd.DataFrame(X4_test, columns=['MARITAL_STATUS'])\n",
    "\n",
    "#X5\n",
    "values = array(X5_test)\n",
    "label_encoder = LabelEncoder()\n",
    "X5_test = label_encoder.fit_transform(values)\n",
    "X5_test=pd.DataFrame(X5_test, columns=['AGE'])\n",
    "\n",
    "#test end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is better than previous encodings\n",
    "\n",
    "#train\n",
    "#X1 - 0\n",
    "balance_limit_ord_map = {'1M':1000000,'1.5M':1500000,'2.5M':2500000, '100K':100000,'200K':200000,'300K':300000,'400K':400000,' 500K':500000,}\n",
    "X1['Balance_Limit_V1']=X1['Balance_Limit_V1'].map(balance_limit_ord_map)\n",
    "\n",
    "#X2 - 1\n",
    "gender_ord_map={'F':1,'M':2}\n",
    "X2['Gender']=X2['Gender'].map(gender_ord_map)\n",
    "\n",
    "#X3 -2\n",
    "educational_status_ord_map={'Other':1,'High School':2,'Graduate':3}\n",
    "X3['EDUCATION_STATUS']=X3['EDUCATION_STATUS'].map(educational_status_ord_map)\n",
    "\n",
    "#X4 - 3\n",
    "marital_status_ord_map={'Other':1, 'Single':2}\n",
    "X4['MARITAL_STATUS']=X4['MARITAL_STATUS'].map(marital_status_ord_map)\n",
    "\n",
    "#X5- 4\n",
    "age_ord_map={'31-45':1,'46-65':2,'Less than 30':0,'More than 65':3}\n",
    "X5['AGE']=X5['AGE'].map(age_ord_map)\n",
    "\n",
    "#train end\n",
    "\n",
    "\n",
    "#test\n",
    "#X1 - 0\n",
    "balance_limit_ord_map = {'1M':1000000,'1.5M':1500000,'2.5M':2500000, '100K':100000,'200K':200000,'300K':300000,'400K':400000,' 500K':500000,}\n",
    "X1_test['Balance_Limit_V1']=X1_test['Balance_Limit_V1'].map(balance_limit_ord_map)\n",
    "\n",
    "#X2 -1\n",
    "gender_ord_map={'F':1,'M':2}\n",
    "X2_test['Gender']=X2_test['Gender'].map(gender_ord_map)\n",
    "\n",
    "#X3 -2\n",
    "educational_status_ord_map={'Other':1,'High School':2,'Graduate':3}\n",
    "X3_test['EDUCATION_STATUS']=X3_test['EDUCATION_STATUS'].map(educational_status_ord_map)\n",
    "\n",
    "#X4 - 3\n",
    "marital_status_ord_map={'Other':1, 'Single':2}\n",
    "X4_test['MARITAL_STATUS']=X4_test['MARITAL_STATUS'].map(marital_status_ord_map)\n",
    "\n",
    "#X5- 4\n",
    "age_ord_map={'31-45':1,'46-65':2,'Less than 30':0,'More than 65':3}\n",
    "X5_test['AGE']=X5_test['AGE'].map(age_ord_map)\n",
    "\n",
    "#test end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2 -1  0  1  2  3  4  5  6  7  8]\n",
      "       PAY_JULY_-2  PAY_JULY_-1  PAY_JULY_0  PAY_JULY_1  PAY_JULY_2  \\\n",
      "0              0.0          1.0         0.0         0.0         0.0   \n",
      "1              0.0          0.0         1.0         0.0         0.0   \n",
      "2              0.0          0.0         0.0         0.0         0.0   \n",
      "3              0.0          0.0         0.0         0.0         1.0   \n",
      "4              0.0          0.0         0.0         0.0         1.0   \n",
      "...            ...          ...         ...         ...         ...   \n",
      "23995          0.0          0.0         1.0         0.0         0.0   \n",
      "23996          0.0          1.0         0.0         0.0         0.0   \n",
      "23997          0.0          0.0         0.0         0.0         0.0   \n",
      "23998          0.0          0.0         0.0         1.0         0.0   \n",
      "23999          0.0          0.0         1.0         0.0         0.0   \n",
      "\n",
      "       PAY_JULY_3  PAY_JULY_4  PAY_JULY_5  PAY_JULY_6  PAY_JULY_7  PAY_JULY_8  \n",
      "0             0.0         0.0         0.0         0.0         0.0         0.0  \n",
      "1             0.0         0.0         0.0         0.0         0.0         0.0  \n",
      "2             0.0         1.0         0.0         0.0         0.0         0.0  \n",
      "3             0.0         0.0         0.0         0.0         0.0         0.0  \n",
      "4             0.0         0.0         0.0         0.0         0.0         0.0  \n",
      "...           ...         ...         ...         ...         ...         ...  \n",
      "23995         0.0         0.0         0.0         0.0         0.0         0.0  \n",
      "23996         0.0         0.0         0.0         0.0         0.0         0.0  \n",
      "23997         0.0         1.0         0.0         0.0         0.0         0.0  \n",
      "23998         0.0         0.0         0.0         0.0         0.0         0.0  \n",
      "23999         0.0         0.0         0.0         0.0         0.0         0.0  \n",
      "\n",
      "[24000 rows x 11 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AkeshalaMarasinghe\\.conda\\envs\\HackStat2.0\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\AkeshalaMarasinghe\\.conda\\envs\\HackStat2.0\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "#train X6 - 5\n",
    "\n",
    "pay_july_le = LabelEncoder()\n",
    "pay_july_ohe = OneHotEncoder()\n",
    "\n",
    "pay_july_labels = pay_july_le.fit_transform(X6['PAY_JULY'])\n",
    "\n",
    "X6['PAY_JULY'] = pay_july_labels\n",
    "print(pay_july_le.classes_)\n",
    "pay_july_arr = pay_july_ohe.fit_transform(X6[['PAY_JULY']]).toarray()\n",
    "pay_july_labels = ['PAY_JULY_' + str(cls_label) for cls_label in pay_july_le.classes_]\n",
    "X6= pd.DataFrame(pay_july_arr,columns = pay_july_labels)\n",
    "\n",
    "\n",
    "#test X6 - 5\n",
    "\n",
    "pay_july_le = LabelEncoder()\n",
    "pay_july_ohe = OneHotEncoder()\n",
    "\n",
    "pay_july_labels = pay_july_le.fit_transform(X6_test['PAY_JULY'])\n",
    "X6_test['PAY_JULY'] = pay_july_labels\n",
    "\n",
    "pay_july_arr = pay_july_ohe.fit_transform(X6_test[['PAY_JULY']]).toarray()\n",
    "pay_july_labels = ['PAY_JULY_' + str(cls_label) for cls_label in pay_july_le.classes_]\n",
    "X6_test= pd.DataFrame(pay_july_arr,columns = pay_july_labels)\n",
    "print(X6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2 -1  0  1  2  3  4  5  6  7  8]\n",
      "       PAY_AUG_-2  PAY_AUG_-1  PAY_AUG_0  PAY_AUG_1  PAY_AUG_2  PAY_AUG_3  \\\n",
      "0             0.0         1.0        0.0        0.0        0.0        0.0   \n",
      "1             0.0         1.0        0.0        0.0        0.0        0.0   \n",
      "2             0.0         0.0        0.0        0.0        0.0        1.0   \n",
      "3             0.0         0.0        1.0        0.0        0.0        0.0   \n",
      "4             0.0         0.0        0.0        0.0        1.0        0.0   \n",
      "...           ...         ...        ...        ...        ...        ...   \n",
      "23995         0.0         0.0        1.0        0.0        0.0        0.0   \n",
      "23996         0.0         1.0        0.0        0.0        0.0        0.0   \n",
      "23997         0.0         0.0        0.0        0.0        0.0        1.0   \n",
      "23998         0.0         1.0        0.0        0.0        0.0        0.0   \n",
      "23999         0.0         0.0        1.0        0.0        0.0        0.0   \n",
      "\n",
      "       PAY_AUG_4  PAY_AUG_5  PAY_AUG_6  PAY_AUG_7  PAY_AUG_8  \n",
      "0            0.0        0.0        0.0        0.0        0.0  \n",
      "1            0.0        0.0        0.0        0.0        0.0  \n",
      "2            0.0        0.0        0.0        0.0        0.0  \n",
      "3            0.0        0.0        0.0        0.0        0.0  \n",
      "4            0.0        0.0        0.0        0.0        0.0  \n",
      "...          ...        ...        ...        ...        ...  \n",
      "23995        0.0        0.0        0.0        0.0        0.0  \n",
      "23996        0.0        0.0        0.0        0.0        0.0  \n",
      "23997        0.0        0.0        0.0        0.0        0.0  \n",
      "23998        0.0        0.0        0.0        0.0        0.0  \n",
      "23999        0.0        0.0        0.0        0.0        0.0  \n",
      "\n",
      "[24000 rows x 11 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AkeshalaMarasinghe\\.conda\\envs\\HackStat2.0\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\AkeshalaMarasinghe\\.conda\\envs\\HackStat2.0\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "#train X7 - 6\n",
    "\n",
    "pay_aug_le = LabelEncoder()\n",
    "pay_aug_ohe = OneHotEncoder()\n",
    "\n",
    "pay_aug_labels = pay_aug_le.fit_transform(X7['PAY_AUG'])\n",
    "X7['PAY_AUG'] = pay_aug_labels\n",
    "\n",
    "pay_aug_arr = pay_aug_ohe.fit_transform(X7[['PAY_AUG']]).toarray()\n",
    "pay_aug_labels = ['PAY_AUG_' + str(cls_label) for cls_label in pay_aug_le.classes_]\n",
    "X7= pd.DataFrame(pay_aug_arr,columns = pay_aug_labels)\n",
    "print(pay_aug_le.classes_)\n",
    "\n",
    "#test X7 - 6\n",
    "\n",
    "pay_aug_le = LabelEncoder()\n",
    "pay_aug_ohe = OneHotEncoder()\n",
    "\n",
    "pay_aug_labels = pay_aug_le.fit_transform(X7_test['PAY_AUG'])\n",
    "X7_test['PAY_AUG'] = pay_aug_labels\n",
    "\n",
    "pay_aug_arr = pay_aug_ohe.fit_transform(X7_test[['PAY_AUG']]).toarray()\n",
    "pay_aug_labels = ['PAY_AUG_' + str(cls_label) for cls_label in pay_aug_le.classes_]\n",
    "X7_test= pd.DataFrame(pay_aug_arr,columns = pay_aug_labels)\n",
    "print(X7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (6000, 42), indices imply (6000, 43)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\.conda\\envs\\HackStat2.0\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[1;34m(blocks, axes)\u001b[0m\n\u001b[0;32m   1677\u001b[0m                 blocks = [\n\u001b[1;32m-> 1678\u001b[1;33m                     \u001b[0mmake_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1679\u001b[0m                 ]\n",
      "\u001b[1;32m~\\.conda\\envs\\HackStat2.0\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mmake_block\u001b[1;34m(values, placement, klass, ndim, dtype, fastpath)\u001b[0m\n\u001b[0;32m   3266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3267\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\HackStat2.0\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, values, placement, ndim)\u001b[0m\n\u001b[0;32m    127\u001b[0m                 \u001b[1;34m\"Wrong number of items passed {val}, placement implies \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m                 \u001b[1;34m\"{mgr}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmgr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m             )\n",
      "\u001b[1;31mValueError\u001b[0m: Wrong number of items passed 42, placement implies 43",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-92cea45b78b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatacreated\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m522\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m511\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m51\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m52\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m53\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m54\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m55\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m56\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m57\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m58\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m622\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m611\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m61\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m62\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m63\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m65\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m66\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m67\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m68\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m17\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m18\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m19\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m21\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m22\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m23\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m \u001b[0mdataset1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatacreated_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m522\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m511\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m51\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m52\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m53\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m54\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m55\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m56\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m57\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m58\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m622\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m611\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m61\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m62\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m63\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m65\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m66\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m67\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m68\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m17\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m18\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m19\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m21\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m22\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\HackStat2.0\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    438\u001b[0m                 \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m                 \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_ndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m         \u001b[1;31m# For data is list-like, or Iterable (will consume into list)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\HackStat2.0\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36minit_ndarray\u001b[1;34m(values, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[0mblock_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcreate_block_manager_from_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\HackStat2.0\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[1;34m(blocks, axes)\u001b[0m\n\u001b[0;32m   1686\u001b[0m         \u001b[0mblocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"values\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1687\u001b[0m         \u001b[0mtot_items\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1688\u001b[1;33m         \u001b[0mconstruction_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtot_items\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\HackStat2.0\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mconstruction_error\u001b[1;34m(tot_items, block_shape, axes, e)\u001b[0m\n\u001b[0;32m   1717\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Empty data passed with indices specified.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1718\u001b[0m     raise ValueError(\n\u001b[1;32m-> 1719\u001b[1;33m         \u001b[1;34m\"Shape of passed values is {0}, indices imply {1}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpassed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimplied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1720\u001b[0m     )\n\u001b[0;32m   1721\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (6000, 42), indices imply (6000, 43)"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X=np.append(X1,X2,axis=1)\n",
    "X=np.append(X,X3,axis=1)\n",
    "X=np.append(X,X4,axis=1)\n",
    "X=np.append(X,X5,axis=1)\n",
    "X=np.append(X,X6,axis=1)\n",
    "X=np.append(X,X7,axis=1)\n",
    "X=np.append(X,X8,axis=1)\n",
    "X=np.append(X,X9,axis=1)\n",
    "X=np.append(X,X10,axis=1)\n",
    "X=np.append(X,X11,axis=1)\n",
    "X=np.append(X,X12,axis=1)\n",
    "X=np.append(X,X13,axis=1)\n",
    "X=np.append(X,X14,axis=1)\n",
    "X=np.append(X,X15,axis=1)\n",
    "X=np.append(X,X16,axis=1)\n",
    "X=np.append(X,X17,axis=1)\n",
    "X=np.append(X,X18,axis=1)\n",
    "X=np.append(X,X19,axis=1)\n",
    "X=np.append(X,X20,axis=1)\n",
    "X=np.append(X,X21,axis=1)\n",
    "X=np.append(X,X22,axis=1)\n",
    "X=np.append(X,X23,axis=1)\n",
    "\n",
    "\n",
    "X_test=np.append(X1_test,X2_test,axis=1)\n",
    "X_test=np.append(X_test,X3_test,axis=1)\n",
    "X_test=np.append(X_test,X4_test,axis=1)\n",
    "X_test=np.append(X_test,X5_test,axis=1)\n",
    "X_test=np.append(X_test,X6_test,axis=1)\n",
    "X_test=np.append(X_test,X7_test,axis=1)\n",
    "X_test=np.append(X_test,X8_test,axis=1)\n",
    "X_test=np.append(X_test,X9_test,axis=1)\n",
    "X_test=np.append(X_test,X10_test,axis=1)\n",
    "X_test=np.append(X_test,X11_test,axis=1)\n",
    "X_test=np.append(X_test,X12_test,axis=1)\n",
    "X_test=np.append(X_test,X13_test,axis=1)\n",
    "X_test=np.append(X_test,X14_test,axis=1)\n",
    "X_test=np.append(X_test,X15_test,axis=1)\n",
    "X_test=np.append(X_test,X16_test,axis=1)\n",
    "X_test=np.append(X_test,X17_test,axis=1)\n",
    "X_test=np.append(X_test,X18_test,axis=1)\n",
    "X_test=np.append(X_test,X19_test,axis=1)\n",
    "X_test=np.append(X_test,X20_test,axis=1)\n",
    "X_test=np.append(X_test,X21_test,axis=1)\n",
    "X_test=np.append(X_test,X22_test,axis=1)\n",
    "X_test=np.append(X_test,X23_test,axis=1)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "x_test = sc.fit_transform(X_test)\n",
    "\n",
    "datacreated=np.append(X,y,axis=1)\n",
    "datacreated_test=x_test\n",
    "\n",
    "#dataset=pd.DataFrame(datacreated, columns=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23])\n",
    "#dataset1=pd.DataFrame(datacreated_test, columns=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22])\n",
    "\n",
    "\n",
    "dataset=pd.DataFrame(datacreated, columns=[0,1,2,3,4,522,511,50,51,52,53,54,55,56,57,58,622,611,60,61,62,63,64,65,66,67,68,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23])\n",
    "dataset1=pd.DataFrame(datacreated_test, columns=[0,1,2,3,4,522,511,50,51,52,53,54,55,56,57,58,622,611,60,61,62,63,64,65,66,67,68,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('train_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1.to_csv('test_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
