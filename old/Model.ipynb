{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from numpy.random import seed\n",
    "seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_preprocessed.csv', header=0)\n",
    "df_test = pd.read_csv('test_preprocessed.csv', header=0)\n",
    "\n",
    "#with all basic features\n",
    "X=df.iloc[:,1:24]\n",
    "y=df.iloc[:,24:25]\n",
    "x_validation_test=df_test.iloc[:,1:24]\n",
    "#X=X.drop(['1','2','3'],axis=1)\n",
    "#x_validation_test=X_validation_test.drop(['1','2','3'],axis=1)\n",
    "\n",
    "#with new features\n",
    "#X=df.iloc[:,1:34]\n",
    "#y=df.iloc[:,34:35]\n",
    "#x_validation_test=df_test.iloc[:,1:34]\n",
    "\n",
    "#less important features are dropped\n",
    "#X = X.drop(['522','511','51','53','54','55','56','57','58'],axis=1)\n",
    "#x_validation_test = x_validation_test.drop(['522','511','51','53','54','55','56','57','58'],axis=1)\n",
    "\n",
    "#check whether some values are missing\n",
    "#X.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(X, y, test_size = 0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Support vector machines\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "\n",
    "clf = svm.SVC(kernel='rbf',degree=2, C=0.4)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "#validation\n",
    "y_pred = clf.predict(x_validation)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_validation, y_pred))\n",
    "print(confusion_matrix(y_validation,y_pred))\n",
    "print(classification_report(y_validation,y_pred))\n",
    "\n",
    "#test\n",
    "y_pred_test = cv.predict(x_validation_test)\n",
    "\n",
    "#normal 0.89 0.45"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#RandomForestGridsearch\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "parameters = {\n",
    "    \"n_estimators\":[5,10,50,100,250],\n",
    "    \"max_depth\":[2,4,8,16,32,None],\n",
    "}\n",
    "cv = GridSearchCV(rfc,parameters,cv=5)\n",
    "cv.fit(x_train, y_train)\n",
    "\n",
    "#validation\n",
    "y_pred = cv.predict(x_validation)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_validation, y_pred))\n",
    "print(confusion_matrix(y_validation,y_pred))\n",
    "print(classification_report(y_validation,y_pred))\n",
    "\n",
    "#test\n",
    "y_pred_test = cv.predict(x_validation_test)\n",
    "\n",
    "#normal - 0.89 0.47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AkeshalaMarasinghe\\.conda\\envs\\HackStat2.0\\lib\\site-packages\\ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.81875\n",
      "[[3545  194]\n",
      " [ 676  385]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.95      0.89      3739\n",
      "         1.0       0.66      0.36      0.47      1061\n",
      "\n",
      "    accuracy                           0.82      4800\n",
      "   macro avg       0.75      0.66      0.68      4800\n",
      "weighted avg       0.80      0.82      0.80      4800\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'x_validation_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-ef18fffa1b12>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m#test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0my_pred_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_validation_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m#normal 0.89 0.47\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_validation_test' is not defined"
     ]
    }
   ],
   "source": [
    "#RandomForestClassifier\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf=RandomForestClassifier(n_estimators=1600,max_features='auto',random_state=42, max_depth=10,bootstrap='True',min_samples_split=5,min_samples_leaf=1)\n",
    "                                  \n",
    "clf.fit(x_train,y_train)\n",
    "\n",
    "#validation\n",
    "y_pred = clf.predict(x_validation)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_validation, y_pred))\n",
    "print(confusion_matrix(y_validation,y_pred))\n",
    "print(classification_report(y_validation,y_pred))\n",
    "\n",
    "#test\n",
    "y_pred_test = clf.predict(x_validation_test)\n",
    "\n",
    "#normal 0.89 0.47\n",
    "#o feature fixed 0.89 0.48 submit 3"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#AdaBoostClassifier\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=9), n_estimators=300,algorithm=\"SAMME.R\", learning_rate=0.0095)\n",
    "ada_clf.fit(x_train,y_train)\n",
    "\n",
    "#validation\n",
    "y_pred = ada_clf.predict(x_validation)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_validation, y_pred))\n",
    "print(confusion_matrix(y_validation,y_pred))\n",
    "print(classification_report(y_validation,y_pred))\n",
    "\n",
    "#test\n",
    "y_pred_test = ada_clf.predict(x_validation_test)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#GradientBoostClassifier\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "model = GradientBoostingClassifier(learning_rate=0.1,max_depth=10,max_features=8,n_estimators=300)\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "#validation\n",
    "y_pred = model.predict(x_validation)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_validation, y_pred))\n",
    "print(confusion_matrix(y_validation,y_pred))\n",
    "print(classification_report(y_validation,y_pred))\n",
    "\n",
    "#test\n",
    "y_pred_test = model.predict(x_validation_test)\n",
    "\n",
    "#normal 0.89 0.47\n",
    "#0 feature fixed 0.88 0.47"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#XGBoostClassifier\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "xgb = XGBClassifier(learning_rate=0.2, max_depth=8,n_estimators= 150,\n",
    " min_child_weight=2, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27,reg_alpha=0.00035) \n",
    "xgb.fit(x_train,y_train)\n",
    "\n",
    "#validation\n",
    "y_pred = xgb.predict(x_validation)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_validation, y_pred))\n",
    "print(confusion_matrix(y_validation,y_pred))\n",
    "print(classification_report(y_validation,y_pred))\n",
    "\n",
    "#test\n",
    "y_pred_test = xgb.predict(x_validation_test)\n",
    "\n",
    "#normal 0.88 0.46"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#XGBoostClassifier with GridSearch\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "xgb=XGBClassifier()\n",
    "parameters = {\n",
    "    \"n_estimators\":[5,10,50,100,250],\n",
    "    \"max_depth\":[2,4,8,16,32,None]\n",
    "}\n",
    "cv = GridSearchCV(rfc,parameters,cv=5)\n",
    "cv.fit(x_train, y_train)\n",
    "\n",
    "#validation\n",
    "y_pred = cv.predict(x_validation)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_validation, y_pred))\n",
    "print(confusion_matrix(y_validation,y_pred))\n",
    "print(classification_report(y_validation,y_pred))\n",
    "\n",
    "#test\n",
    "y_pred_test = cv.predict(x_validation_test)\n",
    "\n",
    "#normal 0.89 0.47"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Random forest with most important feature selection\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create the RFE object and rank each\n",
    "clf_rf_3 = RandomForestClassifier(n_estimators=100,max_features='auto',random_state=0, max_depth=10)      \n",
    "rfe = RFE(estimator=clf_rf_3, n_features_to_select=21, step=1)\n",
    "rfe = rfe.fit(x_train, y_train)\n",
    "print('Chosen best features by rfe:',x_train.columns[rfe.support_])\n",
    "\n",
    "x_train_2 = rfe.transform(x_train)\n",
    "x_test_2 = rfe.transform(x_validation)\n",
    "\n",
    "#random forest classifier with n_estimators=10 (default)\n",
    "clf_rf_2 = RandomForestClassifier()      \n",
    "clr_rf_2 = clf_rf_2.fit(x_train_2,y_train)\n",
    "\n",
    "#validation\n",
    "y_pred=clf_rf_2.predict(x_test_2)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_validation, y_pred))\n",
    "print(confusion_matrix(y_validation,y_pred))\n",
    "print(classification_report(y_validation,y_pred))\n",
    "\n",
    "#test\n",
    "#y_pred_test = clf_rf_2.predict(x_validation_test)\n",
    "\n",
    "#normal 0.88 0.42"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Optimal number of features\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# The \"accuracy\" scoring is proportional to the number of correct classifications\n",
    "clf_rf_4 = RandomForestClassifier(n_estimators=100,max_features='auto',random_state=0, max_depth=10) \n",
    "rfecv = RFECV(estimator=clf_rf_4, step=1, cv=5,scoring='accuracy')   #5-fold cross-validation\n",
    "rfecv = rfecv.fit(x_train, y_train)\n",
    "\n",
    "print('Optimal number of features :', rfecv.n_features_)\n",
    "print('Best features :', x_train.columns[rfecv.support_])\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score of number of selected features\")\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "plt.show()\n",
    "\n",
    "#Optimal number of features : 17\n",
    "#Best features : Index(['0', '4', '5', '6', '7', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22'], dtype='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# random forest optimization\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from pprint import pprint\n",
    "\n",
    "rf = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "# Look at parameters used by our current forest\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(rf.get_params())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(x_train, y_train)\n",
    "\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def evaluate(model, test_features, test_labels):\n",
    "    from sklearn import metrics\n",
    "    y_pred = model.predict(test_features)\n",
    "    errors = abs(y_pred - test_labels)\n",
    "    mape = 100 * np.mean(errors / test_labels)\n",
    "    accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    \n",
    "    return accuracy,y_pred\n",
    "\n",
    "base_model = RandomForestClassifier(n_estimators=100,max_features='auto',random_state=42,max_depth=10)\n",
    "base_model.fit(x_train, y_train)\n",
    "base_accuracy,y_pred_old = evaluate(base_model, x_validation, y_validation)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_validation, y_pred_old))\n",
    "print(confusion_matrix(y_validation,y_pred_old))\n",
    "print(classification_report(y_validation,y_pred_old))\n",
    "\n",
    "best_random = rf_random.best_estimator_\n",
    "random_accuracy,y_pred = evaluate(best_random, x_validation,  y_validation)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_validation, y_pred))\n",
    "print(confusion_matrix(y_validation,y_pred))\n",
    "print(classification_report(y_validation,y_pred))\n",
    "\n",
    "print('Improvement of {:0.2f}%.'.format( 100 * (random_accuracy - base_accuracy) / base_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=pd.DataFrame({'NEXT_MONTH_DEFAULT':y_pred_test})\n",
    "df_test.to_csv('Submissions/Submit4.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
