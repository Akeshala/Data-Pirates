{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import seaborn as sns\n",
    "from numpy.random import seed\n",
    "seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>62</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.190433</td>\n",
       "      <td>0.812251</td>\n",
       "      <td>1.248158</td>\n",
       "      <td>-0.914476</td>\n",
       "      <td>0.197792</td>\n",
       "      <td>-0.37479</td>\n",
       "      <td>-0.312883</td>\n",
       "      <td>-0.388689</td>\n",
       "      <td>-0.701784</td>\n",
       "      <td>-0.672441</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.639372</td>\n",
       "      <td>-0.408977</td>\n",
       "      <td>0.486785</td>\n",
       "      <td>-0.752033</td>\n",
       "      <td>-0.250771</td>\n",
       "      <td>-0.139201</td>\n",
       "      <td>0.672060</td>\n",
       "      <td>4.181041</td>\n",
       "      <td>-0.310064</td>\n",
       "      <td>12.420728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.190433</td>\n",
       "      <td>-1.231147</td>\n",
       "      <td>0.143553</td>\n",
       "      <td>-0.914476</td>\n",
       "      <td>-1.235483</td>\n",
       "      <td>-0.37479</td>\n",
       "      <td>-0.312883</td>\n",
       "      <td>-0.388689</td>\n",
       "      <td>-0.701784</td>\n",
       "      <td>-0.672441</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.509664</td>\n",
       "      <td>-0.381381</td>\n",
       "      <td>-0.091480</td>\n",
       "      <td>0.246894</td>\n",
       "      <td>3.519398</td>\n",
       "      <td>0.572425</td>\n",
       "      <td>0.773195</td>\n",
       "      <td>1.919809</td>\n",
       "      <td>-0.283927</td>\n",
       "      <td>0.504629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-1.039983</td>\n",
       "      <td>-1.231147</td>\n",
       "      <td>0.143553</td>\n",
       "      <td>1.093522</td>\n",
       "      <td>0.197792</td>\n",
       "      <td>-0.37479</td>\n",
       "      <td>-0.312883</td>\n",
       "      <td>-0.388689</td>\n",
       "      <td>1.800614</td>\n",
       "      <td>1.899171</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.580705</td>\n",
       "      <td>-0.673521</td>\n",
       "      <td>-0.661631</td>\n",
       "      <td>-0.651241</td>\n",
       "      <td>-0.338100</td>\n",
       "      <td>-0.245496</td>\n",
       "      <td>-0.297432</td>\n",
       "      <td>-0.309695</td>\n",
       "      <td>-0.310064</td>\n",
       "      <td>-0.290551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.792159</td>\n",
       "      <td>-1.231147</td>\n",
       "      <td>1.248158</td>\n",
       "      <td>1.093522</td>\n",
       "      <td>0.197792</td>\n",
       "      <td>-0.37479</td>\n",
       "      <td>3.196084</td>\n",
       "      <td>-0.388689</td>\n",
       "      <td>0.132349</td>\n",
       "      <td>0.184763</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087016</td>\n",
       "      <td>-0.020458</td>\n",
       "      <td>0.046396</td>\n",
       "      <td>0.089383</td>\n",
       "      <td>-0.240150</td>\n",
       "      <td>-0.176627</td>\n",
       "      <td>-0.206529</td>\n",
       "      <td>-0.182234</td>\n",
       "      <td>-0.197717</td>\n",
       "      <td>-0.198009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.190433</td>\n",
       "      <td>-1.231147</td>\n",
       "      <td>1.248158</td>\n",
       "      <td>-0.914476</td>\n",
       "      <td>0.197792</td>\n",
       "      <td>-0.37479</td>\n",
       "      <td>3.196084</td>\n",
       "      <td>2.572751</td>\n",
       "      <td>0.132349</td>\n",
       "      <td>0.184763</td>\n",
       "      <td>...</td>\n",
       "      <td>1.985142</td>\n",
       "      <td>2.248240</td>\n",
       "      <td>2.479921</td>\n",
       "      <td>2.620791</td>\n",
       "      <td>-0.338100</td>\n",
       "      <td>0.122569</td>\n",
       "      <td>0.100272</td>\n",
       "      <td>0.168286</td>\n",
       "      <td>0.145013</td>\n",
       "      <td>0.118660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23995</td>\n",
       "      <td>1.190433</td>\n",
       "      <td>-1.231147</td>\n",
       "      <td>0.143553</td>\n",
       "      <td>1.093522</td>\n",
       "      <td>0.197792</td>\n",
       "      <td>-0.37479</td>\n",
       "      <td>-0.312883</td>\n",
       "      <td>-0.388689</td>\n",
       "      <td>0.132349</td>\n",
       "      <td>0.184763</td>\n",
       "      <td>...</td>\n",
       "      <td>2.304322</td>\n",
       "      <td>0.690799</td>\n",
       "      <td>-0.152537</td>\n",
       "      <td>-0.385138</td>\n",
       "      <td>0.160799</td>\n",
       "      <td>0.572425</td>\n",
       "      <td>-0.013186</td>\n",
       "      <td>-0.115496</td>\n",
       "      <td>0.010412</td>\n",
       "      <td>-0.235989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23996</td>\n",
       "      <td>-0.296511</td>\n",
       "      <td>-1.231147</td>\n",
       "      <td>0.143553</td>\n",
       "      <td>-0.914476</td>\n",
       "      <td>0.197792</td>\n",
       "      <td>-0.37479</td>\n",
       "      <td>-0.312883</td>\n",
       "      <td>-0.388689</td>\n",
       "      <td>-0.701784</td>\n",
       "      <td>-0.672441</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.626453</td>\n",
       "      <td>-0.534323</td>\n",
       "      <td>-0.577045</td>\n",
       "      <td>-0.651241</td>\n",
       "      <td>-0.230291</td>\n",
       "      <td>-0.101297</td>\n",
       "      <td>0.213778</td>\n",
       "      <td>-0.301474</td>\n",
       "      <td>-0.310064</td>\n",
       "      <td>-0.290551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23997</td>\n",
       "      <td>-1.039983</td>\n",
       "      <td>-1.231147</td>\n",
       "      <td>-0.961053</td>\n",
       "      <td>-0.914476</td>\n",
       "      <td>0.197792</td>\n",
       "      <td>-0.37479</td>\n",
       "      <td>-0.312883</td>\n",
       "      <td>-0.388689</td>\n",
       "      <td>1.800614</td>\n",
       "      <td>-0.672441</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.637099</td>\n",
       "      <td>-0.349851</td>\n",
       "      <td>-0.326191</td>\n",
       "      <td>-0.328903</td>\n",
       "      <td>-0.338100</td>\n",
       "      <td>-0.245496</td>\n",
       "      <td>0.952494</td>\n",
       "      <td>-0.042026</td>\n",
       "      <td>-0.181874</td>\n",
       "      <td>-0.121410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23998</td>\n",
       "      <td>-0.792159</td>\n",
       "      <td>-1.231147</td>\n",
       "      <td>0.143553</td>\n",
       "      <td>1.093522</td>\n",
       "      <td>0.197792</td>\n",
       "      <td>2.66816</td>\n",
       "      <td>-0.312883</td>\n",
       "      <td>-0.388689</td>\n",
       "      <td>0.132349</td>\n",
       "      <td>0.184763</td>\n",
       "      <td>...</td>\n",
       "      <td>0.415051</td>\n",
       "      <td>0.144632</td>\n",
       "      <td>-0.468420</td>\n",
       "      <td>0.163784</td>\n",
       "      <td>4.703723</td>\n",
       "      <td>-0.106077</td>\n",
       "      <td>-0.230509</td>\n",
       "      <td>-0.186951</td>\n",
       "      <td>3.084685</td>\n",
       "      <td>-0.192128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23999</td>\n",
       "      <td>-0.792159</td>\n",
       "      <td>-1.231147</td>\n",
       "      <td>-0.961053</td>\n",
       "      <td>1.093522</td>\n",
       "      <td>1.631067</td>\n",
       "      <td>-0.37479</td>\n",
       "      <td>-0.312883</td>\n",
       "      <td>-0.388689</td>\n",
       "      <td>0.132349</td>\n",
       "      <td>0.184763</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035372</td>\n",
       "      <td>-0.107120</td>\n",
       "      <td>-0.133121</td>\n",
       "      <td>-0.396247</td>\n",
       "      <td>-0.216139</td>\n",
       "      <td>-0.171883</td>\n",
       "      <td>-0.216195</td>\n",
       "      <td>-0.245964</td>\n",
       "      <td>-0.245969</td>\n",
       "      <td>-0.235989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24000 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4       51        52  \\\n",
       "0      1.190433  0.812251  1.248158 -0.914476  0.197792 -0.37479 -0.312883   \n",
       "1      1.190433 -1.231147  0.143553 -0.914476 -1.235483 -0.37479 -0.312883   \n",
       "2     -1.039983 -1.231147  0.143553  1.093522  0.197792 -0.37479 -0.312883   \n",
       "3     -0.792159 -1.231147  1.248158  1.093522  0.197792 -0.37479  3.196084   \n",
       "4      1.190433 -1.231147  1.248158 -0.914476  0.197792 -0.37479  3.196084   \n",
       "...         ...       ...       ...       ...       ...      ...       ...   \n",
       "23995  1.190433 -1.231147  0.143553  1.093522  0.197792 -0.37479 -0.312883   \n",
       "23996 -0.296511 -1.231147  0.143553 -0.914476  0.197792 -0.37479 -0.312883   \n",
       "23997 -1.039983 -1.231147 -0.961053 -0.914476  0.197792 -0.37479 -0.312883   \n",
       "23998 -0.792159 -1.231147  0.143553  1.093522  0.197792  2.66816 -0.312883   \n",
       "23999 -0.792159 -1.231147 -0.961053  1.093522  1.631067 -0.37479 -0.312883   \n",
       "\n",
       "             62         7         8  ...        13        14        15  \\\n",
       "0     -0.388689 -0.701784 -0.672441  ... -0.639372 -0.408977  0.486785   \n",
       "1     -0.388689 -0.701784 -0.672441  ... -0.509664 -0.381381 -0.091480   \n",
       "2     -0.388689  1.800614  1.899171  ... -0.580705 -0.673521 -0.661631   \n",
       "3     -0.388689  0.132349  0.184763  ... -0.087016 -0.020458  0.046396   \n",
       "4      2.572751  0.132349  0.184763  ...  1.985142  2.248240  2.479921   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "23995 -0.388689  0.132349  0.184763  ...  2.304322  0.690799 -0.152537   \n",
       "23996 -0.388689 -0.701784 -0.672441  ... -0.626453 -0.534323 -0.577045   \n",
       "23997 -0.388689  1.800614 -0.672441  ... -0.637099 -0.349851 -0.326191   \n",
       "23998 -0.388689  0.132349  0.184763  ...  0.415051  0.144632 -0.468420   \n",
       "23999 -0.388689  0.132349  0.184763  ...  0.035372 -0.107120 -0.133121   \n",
       "\n",
       "             16        17        18        19        20        21         22  \n",
       "0     -0.752033 -0.250771 -0.139201  0.672060  4.181041 -0.310064  12.420728  \n",
       "1      0.246894  3.519398  0.572425  0.773195  1.919809 -0.283927   0.504629  \n",
       "2     -0.651241 -0.338100 -0.245496 -0.297432 -0.309695 -0.310064  -0.290551  \n",
       "3      0.089383 -0.240150 -0.176627 -0.206529 -0.182234 -0.197717  -0.198009  \n",
       "4      2.620791 -0.338100  0.122569  0.100272  0.168286  0.145013   0.118660  \n",
       "...         ...       ...       ...       ...       ...       ...        ...  \n",
       "23995 -0.385138  0.160799  0.572425 -0.013186 -0.115496  0.010412  -0.235989  \n",
       "23996 -0.651241 -0.230291 -0.101297  0.213778 -0.301474 -0.310064  -0.290551  \n",
       "23997 -0.328903 -0.338100 -0.245496  0.952494 -0.042026 -0.181874  -0.121410  \n",
       "23998  0.163784  4.703723 -0.106077 -0.230509 -0.186951  3.084685  -0.192128  \n",
       "23999 -0.396247 -0.216139 -0.171883 -0.216195 -0.245964 -0.245969  -0.235989  \n",
       "\n",
       "[24000 rows x 24 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train_preprocessed.csv', header=0)\n",
    "df_test = pd.read_csv('test_preprocessed.csv', header=0)\n",
    "\n",
    "#with all basic features\n",
    "#X=df.iloc[:,1:24]\n",
    "#y=df.iloc[:,24:25]\n",
    "#X_validation_test=df_test.iloc[:,1:24]\n",
    "#X=X.drop(['1','2','3'],axis=1)\n",
    "#X_validation_test=X_validation_test.drop(['1','2','3'],axis=1)\n",
    "\n",
    "#with new features\n",
    "X=df.iloc[:,1:44]\n",
    "y=df.iloc[:,44:45]\n",
    "x_validation_test=df_test.iloc[:,1:44]\n",
    "\n",
    "#less important features are dropped\n",
    "X = X.drop(['522','511','51','53','54','55','56','57','58','50','622','611','61','63','64','65','66','67','68','60'],axis=1)\n",
    "#x_validation_test = x_validation_test.drop(['522','511','51','53','54','55','56','57','58','50','622','611','61','63','64','65','66','67','68','60'],axis=1)\n",
    "X\n",
    "#check whether some values are missing\n",
    "#X.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(X, y, test_size = 0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Support vector machines\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "\n",
    "clf = svm.SVC(kernel='rbf',degree=2, C=0.4)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "#validation\n",
    "y_pred = clf.predict(x_validation)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_validation, y_pred))\n",
    "print(confusion_matrix(y_validation,y_pred))\n",
    "print(classification_report(y_validation,y_pred))\n",
    "\n",
    "#test\n",
    "y_pred_test = cv.predict(x_validation_test)\n",
    "\n",
    "#normal 0.89 0.45"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#RandomForestGridsearch\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "parameters = {\n",
    "    \"n_estimators\":[5,10,50,100,250],\n",
    "    \"max_depth\":[2,4,8,16,32,None],\n",
    "}\n",
    "cv = GridSearchCV(rfc,parameters,cv=5)\n",
    "cv.fit(x_train, y_train)\n",
    "\n",
    "#validation\n",
    "y_pred = cv.predict(x_validation)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_validation, y_pred))\n",
    "print(confusion_matrix(y_validation,y_pred))\n",
    "print(classification_report(y_validation,y_pred))\n",
    "\n",
    "#test\n",
    "y_pred_test = cv.predict(x_validation_test)\n",
    "\n",
    "#normal - 0.89 0.47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AkeshalaMarasinghe\\.conda\\envs\\HackStat2.0\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8179166666666666\n",
      "[[3557  182]\n",
      " [ 692  369]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.95      0.89      3739\n",
      "         1.0       0.67      0.35      0.46      1061\n",
      "\n",
      "    accuracy                           0.82      4800\n",
      "   macro avg       0.75      0.65      0.67      4800\n",
      "weighted avg       0.80      0.82      0.79      4800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#RandomForestClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf=RandomForestClassifier(n_estimators=100,max_features='auto',random_state=0,\n",
    "                          max_depth=10)\n",
    "clf.fit(x_train,y_train)\n",
    "\n",
    "#validation\n",
    "y_pred = clf.predict(x_validation)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_validation, y_pred))\n",
    "print(confusion_matrix(y_validation,y_pred))\n",
    "print(classification_report(y_validation,y_pred))\n",
    "\n",
    "#test\n",
    "#y_pred_test = clf.predict(x_validation_test)\n",
    "\n",
    "#normal 0.89 0.47\n",
    "#o feature fixed 0.89 0.48 submit 3"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#AdaBoostClassifier\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=9), n_estimators=300,algorithm=\"SAMME.R\", learning_rate=0.0095)\n",
    "ada_clf.fit(x_train,y_train)\n",
    "\n",
    "#validation\n",
    "y_pred = ada_clf.predict(x_validation)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_validation, y_pred))\n",
    "print(confusion_matrix(y_validation,y_pred))\n",
    "print(classification_report(y_validation,y_pred))\n",
    "\n",
    "#test\n",
    "y_pred_test = ada_clf.predict(x_validation_test)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#GradientBoostClassifier\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "model = GradientBoostingClassifier(learning_rate=0.1,max_depth=10,max_features=8,n_estimators=300)\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "#validation\n",
    "y_pred = model.predict(x_validation)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_validation, y_pred))\n",
    "print(confusion_matrix(y_validation,y_pred))\n",
    "print(classification_report(y_validation,y_pred))\n",
    "\n",
    "#test\n",
    "y_pred_test = model.predict(x_validation_test)\n",
    "\n",
    "#normal 0.89 0.47\n",
    "#0 feature fixed 0.88 0.47"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#XGBoostClassifier\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "xgb = XGBClassifier(learning_rate=0.2, max_depth=8,n_estimators= 150,\n",
    " min_child_weight=2, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27,reg_alpha=0.00035) \n",
    "xgb.fit(x_train,y_train)\n",
    "\n",
    "#validation\n",
    "y_pred = xgb.predict(x_validation)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_validation, y_pred))\n",
    "print(confusion_matrix(y_validation,y_pred))\n",
    "print(classification_report(y_validation,y_pred))\n",
    "\n",
    "#test\n",
    "y_pred_test = xgb.predict(x_validation_test)\n",
    "\n",
    "#normal 0.88 0.46"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#XGBoostClassifier with GridSearch\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "xgb=XGBClassifier()\n",
    "parameters = {\n",
    "    \"n_estimators\":[5,10,50,100,250],\n",
    "    \"max_depth\":[2,4,8,16,32,None]\n",
    "}\n",
    "cv = GridSearchCV(rfc,parameters,cv=5)\n",
    "cv.fit(x_train, y_train)\n",
    "\n",
    "#validation\n",
    "y_pred = cv.predict(x_validation)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_validation, y_pred))\n",
    "print(confusion_matrix(y_validation,y_pred))\n",
    "print(classification_report(y_validation,y_pred))\n",
    "\n",
    "#test\n",
    "y_pred_test = cv.predict(x_validation_test)\n",
    "\n",
    "#normal 0.89 0.47"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Random forest with most important feature selection\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create the RFE object and rank each\n",
    "clf_rf_3 = RandomForestClassifier(n_estimators=100,max_features='auto',random_state=0, max_depth=10)      \n",
    "rfe = RFE(estimator=clf_rf_3, n_features_to_select=23, step=1)\n",
    "rfe = rfe.fit(x_train, y_train)\n",
    "print('Chosen best features by rfe:',x_train.columns[rfe.support_])\n",
    "\n",
    "x_train_2 = rfe.transform(x_train)\n",
    "x_test_2 = rfe.transform(x_validation)\n",
    "\n",
    "#random forest classifier with n_estimators=10 (default)\n",
    "clf_rf_2 = RandomForestClassifier()      \n",
    "clr_rf_2 = clf_rf_2.fit(x_train_2,y_train)\n",
    "\n",
    "#validation\n",
    "y_pred=clf_rf_2.predict(x_test_2)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_validation, y_pred))\n",
    "print(confusion_matrix(y_validation,y_pred))\n",
    "print(classification_report(y_validation,y_pred))\n",
    "\n",
    "#test\n",
    "#y_pred_test = clf_rf_2.predict(x_validation_test)\n",
    "\n",
    "#normal 0.88 0.42"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Optimal number of features\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# The \"accuracy\" scoring is proportional to the number of correct classifications\n",
    "clf_rf_4 = RandomForestClassifier(n_estimators=100,max_features='auto',random_state=0, max_depth=10) \n",
    "rfecv = RFECV(estimator=clf_rf_4, step=1, cv=5,scoring='accuracy')   #5-fold cross-validation\n",
    "rfecv = rfecv.fit(x_train, y_train)\n",
    "\n",
    "print('Optimal number of features :', rfecv.n_features_)\n",
    "print('Best features :', x_train.columns[rfecv.support_])\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score of number of selected features\")\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "plt.show()\n",
    "\n",
    "#Optimal number of features : 17\n",
    "#Best features : Index(['0', '4', '5', '6', '7', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22'], dtype='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# random forest optimization\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from pprint import pprint\n",
    "\n",
    "rf = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "# Look at parameters used by our current forest\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(rf.get_params())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(x_train, y_train)\n",
    "\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def evaluate(model, test_features, test_labels):\n",
    "    y_pred = cv.predict(test_features)\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(test_labels, y_pred))\n",
    "    print(confusion_matrix(test_labels,y_pred))\n",
    "    print(classification_report(test_labels,y_pred))\n",
    "    \n",
    "    y_pred = model.predict(test_features)\n",
    "    errors = abs(y_pred - test_labels)\n",
    "    mape = 100 * np.mean(errors / test_labels)\n",
    "    accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    \n",
    "    return accuracy,y_pred\n",
    "\n",
    "base_model = RandomForestClassifier(n_estimators=100,max_features='auto',random_state=42,max_depth=10)\n",
    "base_model.fit(x_train, y_train)\n",
    "base_accuracy,y_pred_old = evaluate(base_model, x_validation, y_validation)\n",
    "\n",
    "best_random = rf_random.best_estimator_\n",
    "random_accuracy,y_pred = evaluate(best_random, x_validation,  y_validation)\n",
    "\n",
    "print('Improvement of {:0.2f}%.'.format( 100 * (random_accuracy - base_accuracy) / base_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=pd.DataFrame({'NEXT_MONTH_DEFAULT':y_pred_test})\n",
    "df_test.to_csv('Submissions/Submit4.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
